<!DOCTYPE html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.58" />
    <meta name="theme" content="VuePress Theme Hope" />
    <meta property="og:url" content="https://aiyin5.github.io/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%BC%8F/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B8%83%E5%B1%80%EF%BC%88Pod%E7%9A%84%E6%94%BE%E7%BD%AE%EF%BC%89.html"><meta property="og:site_name" content="è‰¾å› çš„åšå®¢"><meta property="og:title" content="åŸºç¡€æ¨¡å¼ è‡ªåŠ¨åŒ–å¸ƒå±€"><meta property="og:description" content="åŸºç¡€æ¨¡å¼ è‡ªåŠ¨åŒ–å¸ƒå±€ 2.5 Automated Placement &nbsp;è‡ªåŠ¨åŒ–å¸ƒå±€ï¼ˆPodçš„æ”¾ç½®ï¼‰ Automated Placement is the core function of the Kubernetes scheduler for assigning new Pods to nodes satisfying container resource requests and honoring scheduling policies. This pattern describes the principles of Kubernetesâ€™ scheduling algorithm and the way to influence the placement decisions from the outside."><meta property="og:type" content="article"><meta property="og:updated_time" content="2023-01-12T05:00:13.000Z"><meta property="og:locale" content="zh-CN"><meta property="article:tag" content="ç¿»è¯‘"><meta property="article:published_time" content="2023-01-05T00:00:00.000Z"><meta property="article:modified_time" content="2023-01-12T05:00:13.000Z"><title>åŸºç¡€æ¨¡å¼ è‡ªåŠ¨åŒ–å¸ƒå±€ | è‰¾å› çš„åšå®¢</title><meta name="description" content="åŸºç¡€æ¨¡å¼ è‡ªåŠ¨åŒ–å¸ƒå±€ 2.5 Automated Placement &nbsp;è‡ªåŠ¨åŒ–å¸ƒå±€ï¼ˆPodçš„æ”¾ç½®ï¼‰ Automated Placement is the core function of the Kubernetes scheduler for assigning new Pods to nodes satisfying container resource requests and honoring scheduling policies. This pattern describes the principles of Kubernetesâ€™ scheduling algorithm and the way to influence the placement decisions from the outside.">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d2025;
      }

      html,
      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.querySelector("html").setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="preload" href="/assets/style-4e49b06b.css" as="style"><link rel="stylesheet" href="/assets/style-4e49b06b.css">
    <link rel="modulepreload" href="/assets/app-e590ba2f.js"><link rel="modulepreload" href="/assets/framework-e28fa486.js"><link rel="modulepreload" href="/assets/è‡ªåŠ¨åŒ–å¸ƒå±€ï¼ˆPodçš„æ”¾ç½®ï¼‰.html-be94ae9d.js"><link rel="modulepreload" href="/assets/è‡ªåŠ¨åŒ–å¸ƒå±€ï¼ˆPodçš„æ”¾ç½®ï¼‰.html-8cff2510.js">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="skip-link sr-only">è·³è‡³ä¸»è¦å…§å®¹</a><!--]--><div class="theme-container has-toc"><!--[--><!--[--><header class="navbar"><div class="navbar-left"><button class="toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><a href="/" class="brand"><img class="logo" src="/rabbitMan.jpg" alt="è‰¾å› çš„åšå®¢"><!----><span class="site-name hide-in-pad">è‰¾å› çš„åšå®¢</span></a><!--[--><!----><!--]--></div><div class="navbar-center"><!--[--><!----><!--]--><!----><!--[--><!----><!--]--></div><div class="navbar-right"><!--[--><!----><!--]--><nav class="nav-links"><div class="nav-item hide-in-mobile"><a href="/" class="nav-link" aria-label="ä¸»é¡µ"><span class="icon iconfont icon-home"></span>ä¸»é¡µ<!----></a></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button class="dropdown-title" type="button" aria-label="è‰¾å› çš„ä¸–ç•Œ"><span class="title"><span class="icon iconfont icon-discover"></span>è‰¾å› çš„ä¸–ç•Œ</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a href="/zh/posts/%E5%85%B3%E4%BA%8E%E8%89%BE%E5%9B%A0/%E5%85%B3%E4%BA%8E%E8%89%BE%E5%9B%A0.html" class="nav-link" aria-label="å…³äºè‰¾å› "><span class="icon iconfont icon-edit"></span>å…³äºè‰¾å› <!----></a></li><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>ç”Ÿæ´»ä½“éªŒ</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/zh/posts/%E5%85%B3%E4%BA%8E%E8%89%BE%E5%9B%A0/%E7%94%9F%E6%B4%BB%E4%BD%93%E9%AA%8C/%E4%B8%8A%E6%B5%B7.html" class="nav-link" aria-label="ä¸Šæµ·"><span class="icon iconfont icon-edit"></span>ä¸Šæµ·<!----></a></li><li class="dropdown-subitem"><a href="/zh/posts/%E5%85%B3%E4%BA%8E%E8%89%BE%E5%9B%A0/%E7%94%9F%E6%B4%BB%E4%BD%93%E9%AA%8C/%E6%9D%AD%E5%B7%9E.html" class="nav-link" aria-label="æ­å·"><span class="icon iconfont icon-edit"></span>æ­å·<!----></a></li><li class="dropdown-subitem"><a href="/zh/posts/%E5%85%B3%E4%BA%8E%E8%89%BE%E5%9B%A0/%E7%94%9F%E6%B4%BB%E4%BD%93%E9%AA%8C/%E5%AE%89%E5%90%89.html" class="nav-link" aria-label="å®‰å‰"><span class="icon iconfont icon-edit"></span>å®‰å‰<!----></a></li><li class="dropdown-subitem"><a href="/zh/posts/%E5%85%B3%E4%BA%8E%E8%89%BE%E5%9B%A0/%E7%94%9F%E6%B4%BB%E4%BD%93%E9%AA%8C/%E5%A4%A7%E7%90%86.html" class="nav-link" aria-label="å¤§ç†"><span class="icon iconfont icon-edit"></span>å¤§ç†<!----></a></li></ul></li><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>å…³äºå¨å¸ˆ</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/zh/posts/%E5%85%B3%E4%BA%8E%E8%89%BE%E5%9B%A0/%E5%85%B3%E4%BA%8E%E5%8E%A8%E5%B8%88/%E8%89%BE%E5%9B%A0%E5%AE%B6%E7%9A%84%E8%8F%9C%E8%B0%B1.html" class="nav-link" aria-label="è‰¾å› å®¶çš„èœè°±"><span class="icon iconfont icon-edit"></span>è‰¾å› å®¶çš„èœè°±<!----></a></li><li class="dropdown-subitem"><a href="/zh/posts/%E5%85%B3%E4%BA%8E%E8%89%BE%E5%9B%A0/%E5%85%B3%E4%BA%8E%E5%8E%A8%E5%B8%88/%E8%89%BE%E5%9B%A0%E5%AE%B6%E7%9A%84%E7%94%9C%E5%93%81.html" class="nav-link" aria-label="è‰¾å› å®¶çš„ç”œå“"><span class="icon iconfont icon-edit"></span>è‰¾å› å®¶çš„ç”œå“<!----></a></li></ul></li><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>è§†é‡</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/zh/posts/å…³äºè‰¾å› /è§†é‡/1" class="nav-link" aria-label="tobeContinue"><span class="icon iconfont icon-edit"></span>tobeContinue<!----></a></li></ul></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button class="dropdown-title" type="button" aria-label="é¡¹ç›®"><span class="title"><span class="icon iconfont icon-edit"></span>é¡¹ç›®</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a href="/zh/posts/%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3/%E9%A3%8E%E6%8E%A7%E5%86%B3%E7%AD%96%E5%BC%95%E6%93%8E.html" class="nav-link" aria-label="é£æ§å†³ç­–å¼•æ“ç›¸å…³"><span class="icon iconfont icon-edit"></span>é£æ§å†³ç­–å¼•æ“ç›¸å…³<!----></a></li><li class="dropdown-item"><a href="/zh/posts/%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3/FreeBe%E7%9B%B8%E5%85%B3.html" class="nav-link" aria-label="FreeBeç›¸å…³"><span class="icon iconfont icon-edit"></span>FreeBeç›¸å…³<!----></a></li><li class="dropdown-item"><a href="/zh/posts/%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3/%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5%E5%8F%8A%E5%8D%9A%E5%AE%A2.html" class="nav-link" aria-label="ä¸ªäººä¸»é¡µåŠåšå®¢"><span class="icon iconfont icon-edit"></span>ä¸ªäººä¸»é¡µåŠåšå®¢<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button class="dropdown-title" type="button" aria-label="æŠ€æœ¯"><span class="title"><span class="icon iconfont icon-edit"></span>æŠ€æœ¯</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>é¢˜è§£</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/zh/posts/%E5%85%B3%E4%BA%8E%E6%8A%80%E6%9C%AF/LeetCode%E9%A2%98%E8%A7%A3/LeetCode%E9%A2%98%E8%A7%A3.html" class="nav-link" aria-label="LeetCodeé¢˜è§£"><span class="icon iconfont icon-edit"></span>LeetCodeé¢˜è§£<!----></a></li></ul></li><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>ç®—æ³•</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/zh/posts/%E5%85%B3%E4%BA%8E%E6%8A%80%E6%9C%AF/%E7%AE%97%E6%B3%95/%E5%9B%BE%E8%AE%BA%E6%95%B4%E7%90%86.html" class="nav-link" aria-label="å›¾è®ºæ•´ç†"><span class="icon iconfont icon-edit"></span>å›¾è®ºæ•´ç†<!----></a></li><li class="dropdown-subitem"><a href="/zh/posts/%E5%85%B3%E4%BA%8E%E6%8A%80%E6%9C%AF/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2%E8%BE%B9%E7%95%8C%E5%88%A4%E6%96%AD.html" class="nav-link" aria-label="äºŒåˆ†æœç´¢è¾¹ç•Œåˆ¤æ–­"><span class="icon iconfont icon-edit"></span>äºŒåˆ†æœç´¢è¾¹ç•Œåˆ¤æ–­<!----></a></li><li class="dropdown-subitem"><a href="/zh/posts/%E5%85%B3%E4%BA%8E%E6%8A%80%E6%9C%AF/%E7%AE%97%E6%B3%95/%E5%B9%B6%E6%9F%A5%E9%9B%86.html" class="nav-link" aria-label="å¹¶æŸ¥é›†"><span class="icon iconfont icon-edit"></span>å¹¶æŸ¥é›†<!----></a></li></ul></li><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>åç«¯</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/zh/posts/%E5%85%B3%E4%BA%8E%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/java%E5%9F%BA%E7%A1%80.html" class="nav-link" aria-label="javaåŸºç¡€"><span class="icon iconfont icon-edit"></span>javaåŸºç¡€<!----></a></li><li class="dropdown-subitem"><a href="/zh/posts/%E5%85%B3%E4%BA%8E%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/%E6%95%B0%E6%8D%AE%E5%BA%93.html" class="nav-link" aria-label="æ•°æ®åº“"><span class="icon iconfont icon-edit"></span>æ•°æ®åº“<!----></a></li><li class="dropdown-subitem"><a href="/zh/posts/%E5%85%B3%E4%BA%8E%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/redis.html" class="nav-link" aria-label="redis"><span class="icon iconfont icon-edit"></span>redis<!----></a></li><li class="dropdown-subitem"><a href="/zh/posts/%E5%85%B3%E4%BA%8E%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6.html" class="nav-link" aria-label="å¼€å‘æ¡†æ¶"><span class="icon iconfont icon-edit"></span>å¼€å‘æ¡†æ¶<!----></a></li><li class="dropdown-subitem"><a href="/zh/posts/%E5%85%B3%E4%BA%8E%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/%E7%9F%A5%E8%AF%86%E9%93%BE%E6%8E%A5.html" class="nav-link" aria-label="çŸ¥è¯†é“¾æ¥"><span class="icon iconfont icon-edit"></span>çŸ¥è¯†é“¾æ¥<!----></a></li></ul></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button class="dropdown-title" type="button" aria-label="æ–‡ç« ç¿»è¯‘"><span class="title"><span class="icon iconfont icon-edit"></span>æ–‡ç« ç¿»è¯‘</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a href="/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E6%A8%A1%E5%BC%8F%E8%AE%BE%E8%AE%A1.html" class="nav-link" aria-label="K8sæ¨¡å¼"><span class="icon iconfont icon-edit"></span>K8sæ¨¡å¼<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><a href="/about/About.html" class="nav-link" aria-label="å…³äº"><span class="icon iconfont icon-discover"></span>å…³äº<!----></a></div></nav><div class="nav-item"><a class="repo-link" href="https://github.com/Aiyin5/Aiyin5.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button class="outlook-button" tabindex="-1" ariahidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="outlook-dropdown"><!----></div></button></div><!----><!--[--><!----><!--]--><button class="toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span class="button-container"><span class="button-top"></span><span class="button-middle"></span><span class="button-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow left"></span></div><aside class="sidebar"><!--[--><!----><!--]--><ul class="sidebar-links"><li><!--[--><a href="/" class="nav-link sidebar-link sidebar-page" aria-label="ä¸»é¡µ"><span class="icon iconfont icon-home"></span>ä¸»é¡µ<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><section class="sidebar-group"><p class="sidebar-heading active"><span class="icon iconfont icon-note"></span><span class="title">æ–‡ç« </span><!----></p><ul class="sidebar-links"><li><section class="sidebar-group"><button class="sidebar-heading clickable"><!----><span class="title">å…³äºæŠ€æœ¯</span><span class="arrow right"></span></button><!----></section></li><li><section class="sidebar-group"><button class="sidebar-heading clickable"><!----><span class="title">å…³äºè‰¾å› </span><span class="arrow right"></span></button><!----></section></li><li><section class="sidebar-group"><button class="sidebar-heading clickable active"><!----><span class="title">æ–‡ç« ç¿»è¯‘</span><span class="arrow down"></span></button><ul class="sidebar-links"><li><section class="sidebar-group"><button class="sidebar-heading clickable active"><!----><span class="title">K8sæ¨¡å¼</span><span class="arrow down"></span></button><ul class="sidebar-links"><li><!--[--><a href="/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E6%A8%A1%E5%BC%8F%E8%AE%BE%E8%AE%A1.html" class="nav-link sidebar-link sidebar-page" aria-label="K8sæ¨¡å¼ç¿»è¯‘"><span class="icon iconfont icon-page"></span>K8sæ¨¡å¼ç¿»è¯‘<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><section class="sidebar-group"><button class="sidebar-heading clickable active"><!----><span class="title">K8såŸºç¡€æ¨¡å¼</span><span class="arrow down"></span></button><ul class="sidebar-links"><li><!--[--><a href="/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%BC%8F/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%BC%8F.html" class="nav-link sidebar-link sidebar-page" aria-label="ç¬¬äºŒç«  åŸºç¡€æ¨¡å¼"><span class="icon iconfont icon-page"></span>ç¬¬äºŒç«  åŸºç¡€æ¨¡å¼<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a href="/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%BC%8F/%E5%8F%AF%E9%A2%84%E6%B5%8B%E7%9A%84%E9%9C%80%E6%B1%82.html" class="nav-link sidebar-link sidebar-page" aria-label="åŸºç¡€æ¨¡å¼-å¯é¢„æµ‹çš„éœ€æ±‚"><span class="icon iconfont icon-page"></span>åŸºç¡€æ¨¡å¼-å¯é¢„æµ‹çš„éœ€æ±‚<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a href="/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%BC%8F/%E5%A3%B0%E6%98%8E%E6%80%A7%E9%83%A8%E7%BD%B2.html" class="nav-link sidebar-link sidebar-page" aria-label="åŸºç¡€æ¨¡å¼ å£°æ˜å¼éƒ¨ç½²"><span class="icon iconfont icon-page"></span>åŸºç¡€æ¨¡å¼ å£°æ˜å¼éƒ¨ç½²<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a href="/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%BC%8F/%E5%81%A5%E5%BA%B7%E6%8E%A2%E9%92%88.html" class="nav-link sidebar-link sidebar-page" aria-label="åŸºç¡€æ¨¡å¼ å¥åº·æ¢é’ˆ"><span class="icon iconfont icon-page"></span>åŸºç¡€æ¨¡å¼ å¥åº·æ¢é’ˆ<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a href="/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%BC%8F/%E6%89%98%E7%AE%A1%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.html" class="nav-link sidebar-link sidebar-page" aria-label="åŸºç¡€æ¨¡å¼ æ‰˜ç®¡ç”Ÿå‘½å‘¨æœŸ"><span class="icon iconfont icon-page"></span>åŸºç¡€æ¨¡å¼ æ‰˜ç®¡ç”Ÿå‘½å‘¨æœŸ<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-current="page" href="/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%BC%8F/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B8%83%E5%B1%80%EF%BC%88Pod%E7%9A%84%E6%94%BE%E7%BD%AE%EF%BC%89.html" class="router-link-active router-link-exact-active nav-link active sidebar-link sidebar-page active" aria-label="åŸºç¡€æ¨¡å¼ è‡ªåŠ¨åŒ–å¸ƒå±€"><span class="icon iconfont icon-page"></span>åŸºç¡€æ¨¡å¼ è‡ªåŠ¨åŒ–å¸ƒå±€<!----></a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a aria-current="page" href="/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%BC%8F/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B8%83%E5%B1%80%EF%BC%88Pod%E7%9A%84%E6%94%BE%E7%BD%AE%EF%BC%89.html#_2-5-automated-placement-è‡ªåŠ¨åŒ–å¸ƒå±€-podçš„æ”¾ç½®" class="router-link-active router-link-exact-active nav-link sidebar-link heading" aria-label="2.5 Automated Placement Â è‡ªåŠ¨åŒ–å¸ƒå±€ï¼ˆPodçš„æ”¾ç½®ï¼‰"><!---->2.5 Automated Placement Â è‡ªåŠ¨åŒ–å¸ƒå±€ï¼ˆPodçš„æ”¾ç½®ï¼‰<!----></a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a aria-current="page" href="/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%BC%8F/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B8%83%E5%B1%80%EF%BC%88Pod%E7%9A%84%E6%94%BE%E7%BD%AE%EF%BC%89.html#_2-5-1-problem-é—®é¢˜" class="router-link-active router-link-exact-active nav-link sidebar-link heading" aria-label="2.5.1 Problem Â é—®é¢˜"><!---->2.5.1 Problem Â é—®é¢˜<!----></a><ul class="sidebar-sub-headers"></ul></li><li class="sidebar-sub-header"><a aria-current="page" href="/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%BC%8F/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B8%83%E5%B1%80%EF%BC%88Pod%E7%9A%84%E6%94%BE%E7%BD%AE%EF%BC%89.html#_2-5-2-solution-è§£å†³æ–¹æ¡ˆ" class="router-link-active router-link-exact-active nav-link sidebar-link heading" aria-label="2.5.2 Solution Â  è§£å†³æ–¹æ¡ˆ"><!---->2.5.2 Solution Â  è§£å†³æ–¹æ¡ˆ<!----></a><ul class="sidebar-sub-headers"></ul></li><li class="sidebar-sub-header"><a aria-current="page" href="/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%BC%8F/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B8%83%E5%B1%80%EF%BC%88Pod%E7%9A%84%E6%94%BE%E7%BD%AE%EF%BC%89.html#_2-5-3-discussion-è®¨è®º" class="router-link-active router-link-exact-active nav-link sidebar-link heading" aria-label="2.5.3 Discussion Â è®¨è®º"><!---->2.5.3 Discussion Â è®¨è®º<!----></a><ul class="sidebar-sub-headers"></ul></li></ul></li></ul><!--]--></li></ul></section></li><li><section class="sidebar-group"><button class="sidebar-heading clickable"><!----><span class="title">K8sçš„ç®€ä»‹</span><span class="arrow right"></span></button><!----></section></li></ul></section></li></ul></section></li><li><section class="sidebar-group"><button class="sidebar-heading clickable"><!----><span class="title">é¡¹ç›®ç›¸å…³</span><span class="arrow right"></span></button><!----></section></li></ul></section></li></ul><!--[--><!----><!--]--></aside><!--[--><main class="page" id="main-content"><!--[--><!----><nav class="breadcrumb disable"></nav><div class="page-title"><h1><span class="icon iconfont icon-page"></span>åŸºç¡€æ¨¡å¼ è‡ªåŠ¨åŒ–å¸ƒå±€</h1><div class="page-info"><span class="author-info" aria-label="ä½œè€…ğŸ–Š" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="author-item" href="http://www.aiyin.xyz" target="_blank" rel="noopener noreferrer">è‰¾å› </a></span><span property="author" content="è‰¾å› "></span></span><!----><span class="date-info" aria-label="å†™ä½œæ—¥æœŸğŸ“…" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2023-01-05T00:00:00.000Z"></span><span class="category-info" aria-label="åˆ†ç±»ğŸŒˆ" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><span class="category-item category4 clickable" role="navigation">æŠ€æœ¯</span><span class="category-item category2 clickable" role="navigation">K8s</span><meta property="articleSection" content="æŠ€æœ¯,K8s"></span><span class="tag-info" aria-label="æ ‡ç­¾ğŸ·" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><span class="tag-item tag-item1 clickable" role="navigation">ç¿»è¯‘</span><meta property="keywords" content="ç¿»è¯‘"></span><span class="reading-time-info" aria-label="é˜…è¯»æ—¶é—´âŒ›" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>å¤§çº¦ 30 åˆ†é’Ÿ</span><meta property="timeRequired" content="PT30M"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><div class="toc-header">æ­¤é¡µå†…å®¹</div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a aria-current="page" href="/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%BC%8F/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B8%83%E5%B1%80%EF%BC%88Pod%E7%9A%84%E6%94%BE%E7%BD%AE%EF%BC%89.html#_2-5-automated-placement-è‡ªåŠ¨åŒ–å¸ƒå±€-podçš„æ”¾ç½®" class="router-link-active router-link-exact-active toc-link level2">2.5 Automated Placement Â è‡ªåŠ¨åŒ–å¸ƒå±€ï¼ˆPodçš„æ”¾ç½®ï¼‰</a></li><ul class="toc-list"><!--[--><li class="toc-item"><a aria-current="page" href="/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%BC%8F/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B8%83%E5%B1%80%EF%BC%88Pod%E7%9A%84%E6%94%BE%E7%BD%AE%EF%BC%89.html#_2-5-1-problem-é—®é¢˜" class="router-link-active router-link-exact-active toc-link level3">2.5.1 Problem Â é—®é¢˜</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%BC%8F/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B8%83%E5%B1%80%EF%BC%88Pod%E7%9A%84%E6%94%BE%E7%BD%AE%EF%BC%89.html#_2-5-2-solution-è§£å†³æ–¹æ¡ˆ" class="router-link-active router-link-exact-active toc-link level3">2.5.2 Solution Â  è§£å†³æ–¹æ¡ˆ</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%BC%8F/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B8%83%E5%B1%80%EF%BC%88Pod%E7%9A%84%E6%94%BE%E7%BD%AE%EF%BC%89.html#_2-5-3-discussion-è®¨è®º" class="router-link-active router-link-exact-active toc-link level3">2.5.3 Discussion Â è®¨è®º</a></li><!----><!--]--></ul><!--]--></ul></div></aside></div><!----><div class="theme-hope-content"><h1 id="åŸºç¡€æ¨¡å¼-è‡ªåŠ¨åŒ–å¸ƒå±€" tabindex="-1"><a class="header-anchor" href="#åŸºç¡€æ¨¡å¼-è‡ªåŠ¨åŒ–å¸ƒå±€" aria-hidden="true">#</a> åŸºç¡€æ¨¡å¼ è‡ªåŠ¨åŒ–å¸ƒå±€</h1><h2 id="_2-5-automated-placement-è‡ªåŠ¨åŒ–å¸ƒå±€-podçš„æ”¾ç½®" tabindex="-1"><a class="header-anchor" href="#_2-5-automated-placement-è‡ªåŠ¨åŒ–å¸ƒå±€-podçš„æ”¾ç½®" aria-hidden="true">#</a> 2.5 Automated Placement Â è‡ªåŠ¨åŒ–å¸ƒå±€ï¼ˆPodçš„æ”¾ç½®ï¼‰</h2><p>Automated Placement is the core function of the Kubernetes scheduler for assigning new Pods to nodes satisfying container resource requests and honoring scheduling policies. This pattern describes the principles of Kubernetesâ€™ scheduling algorithm and the way to influence the placement decisions from the outside.</p><p>è‡ªåŠ¨åŒ–æ”¾ç½®ï¼ˆåˆ†é…ï¼Ÿè°ƒåº¦ï¼‰æ˜¯Kubernetesè°ƒåº¦å™¨çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œç”¨äºå°†æ–°PODåˆ†é…ç»™æ»¡è¶³å®¹å™¨èµ„æºè¯·æ±‚çš„èŠ‚ç‚¹ï¼Œå¹¶éµå®ˆè°ƒåº¦ç­–ç•¥ã€‚è¯¥æ¨¡å¼æè¿°äº†Kubernetesè°ƒåº¦ç®—æ³•çš„åŸç†ä»¥åŠä»å¤–éƒ¨å½±å“å¸ƒå±€å†³ç­–çš„æ–¹å¼ã€‚</p><h3 id="_2-5-1-problem-é—®é¢˜" tabindex="-1"><a class="header-anchor" href="#_2-5-1-problem-é—®é¢˜" aria-hidden="true">#</a> 2.5.1 Problem Â é—®é¢˜</h3><p>A reasonably sized microservices-based system consists of tens or even hundreds of isolated processes. Containers and Pods do provide nice abstractions for packaging and deployment but do not solve the problem of placing these processes on suitable nodes. With a large and ever-growing number of microservices, assigning and placing them individually to nodes is not a manageable activity.</p><p>ä¸€ä¸ªè§„æ¨¡åˆç†çš„åŸºäºå¾®æœåŠ¡çš„ç³»ç»Ÿç”±æ•°åä¸ªç”šè‡³æ•°ç™¾ä¸ªå­¤ç«‹çš„è¿›ç¨‹ç»„æˆã€‚å®¹å™¨å’Œpodç¡®å®ä¸ºæ‰“åŒ…å’Œéƒ¨ç½²æä¾›äº†å¾ˆå¥½çš„æŠ½è±¡ï¼Œä½†å¹¶ä¸èƒ½è§£å†³å°†è¿™äº›è¿›ç¨‹æ”¾ç½®åœ¨åˆé€‚èŠ‚ç‚¹ä¸Šçš„é—®é¢˜ã€‚éšç€å¾®å‹æœåŠ¡æ•°é‡çš„ä¸æ–­å¢åŠ ï¼Œå°†å®ƒä»¬å•ç‹¬åˆ†é…å’Œæ”¾ç½®åˆ°èŠ‚ç‚¹å¹¶ä¸æ˜¯ä¸€é¡¹å¯ç®¡ç†çš„æ´»åŠ¨ã€‚</p><p>Containers have dependencies among themselves, dependencies to nodes, and resource demands, and all of that changes over time too. The resources available on a cluster also vary over time, through shrinking or extending the cluster, or by having it consumed by already placed containers. The way we place containers impacts the availability, performance, and capacity of the distributed systems as well. <em>All of that makes scheduling containers to nodes a moving target that has to be shot on the move.</em>ï¼ˆè¿™å¥ç¿»è¯‘æœ‰é—®é¢˜ï¼Œæš‚æ—¶è·³è¿‡ï¼‰</p><p>å®¹å™¨ä¹‹é—´æœ‰ä¾èµ–å…³ç³»ã€å¯¹èŠ‚ç‚¹çš„ä¾èµ–å…³ç³»å’Œèµ„æºéœ€æ±‚ï¼Œæ‰€æœ‰è¿™äº›éƒ½ä¼šéšç€æ—¶é—´çš„æ¨ç§»è€Œå˜åŒ–ã€‚é›†ç¾¤ä¸Šå¯ç”¨çš„èµ„æºä¹Ÿä¼šéšç€æ—¶é—´çš„æ¨ç§»è€Œå˜åŒ–ï¼Œé€šè¿‡æ”¶ç¼©æˆ–æ‰©å±•é›†ç¾¤ï¼Œæˆ–è€…è®©å·²ç»æ”¾ç½®çš„å®¹å™¨æ¶ˆè€—é›†ç¾¤ã€‚æˆ‘ä»¬æ”¾ç½®å®¹å™¨çš„æ–¹å¼ä¹Ÿä¼šå½±å“åˆ†å¸ƒå¼ç³»ç»Ÿçš„å¯ç”¨æ€§ã€æ€§èƒ½å’Œå®¹é‡ã€‚æ‰€æœ‰è¿™äº›éƒ½ä½¿å¾—å°†å®¹å™¨è°ƒåº¦åˆ°èŠ‚ç‚¹è¿™ä¸€è¿‡ç¨‹ä¸­çš„ç›®æ ‡ï¼Œå¿…é¡»åœ¨è¿›è¡Œä¸­å®Œæˆã€‚</p><h3 id="_2-5-2-solution-è§£å†³æ–¹æ¡ˆ" tabindex="-1"><a class="header-anchor" href="#_2-5-2-solution-è§£å†³æ–¹æ¡ˆ" aria-hidden="true">#</a> 2.5.2 Solution Â  è§£å†³æ–¹æ¡ˆ</h3><p>In Kubernetes, assigning Pods to nodes is done by the scheduler. It is an area that is highly configurable, still evolving, and changing rapidly as of this writing. In this chapter, we cover the main scheduling control mechanisms, driving forces that affect the placement, why to choose one or the other option, and the resulting consequences. The Kubernetes scheduler is a potent and time-saving <a href="http://tool.It" target="_blank" rel="noopener noreferrer">tool.It<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> plays a fundamental role in the Kubernetes platform as a whole, but similarly to other Kubernetes components (API Server, Kubelet), it can be run in isolation or not used at all.</p><p>åœ¨Kubernetesä¸­ï¼Œå°†Podåˆ†é…ç»™èŠ‚ç‚¹æ˜¯ç”±è°ƒåº¦å™¨å®Œæˆçš„ã€‚åœ¨æ’°å†™æœ¬æ–‡æ—¶ï¼Œè¿™æ˜¯ä¸€ä¸ªé«˜åº¦å¯é…ç½®ã€ä»åœ¨å‘å±•å’Œå¿«é€Ÿå˜åŒ–çš„é¢†åŸŸã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸»è¦çš„è°ƒåº¦æ§åˆ¶æœºåˆ¶ã€å½±å“å¸ƒå±€çš„é©±åŠ¨åŠ›ã€ä¸ºä»€ä¹ˆé€‰æ‹©ä¸€ä¸ªæˆ–å¦ä¸€ä¸ªé€‰é¡¹ä»¥åŠç”±æ­¤äº§ç”Ÿçš„åæœã€‚Kubernetesè°ƒåº¦å™¨æ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§ä¸”èŠ‚çœæ—¶é—´çš„å·¥å…·ã€‚å®ƒåœ¨æ•´ä¸ªKuberneteså¹³å°ä¸­èµ·ç€åŸºç¡€æ€§ä½œç”¨ï¼Œä½†ä¸å…¶ä»–Kubernetesç»„ä»¶ï¼ˆAPIæœåŠ¡å™¨ã€Kubeletï¼‰ç±»ä¼¼ï¼Œå®ƒå¯ä»¥å•ç‹¬è¿è¡Œæˆ–æ ¹æœ¬ä¸ä½¿ç”¨ã€‚</p><p>At a very high level, the main operation the Kubernetes scheduler performs is to retrieve each newly created Pod definition from the API Server and assign it to a node. It finds a suitable node for every Pod (as long as there is such a node), whether that is for the initial application placement, scaling up, or when moving an application from an unhealthy node to a healthier one. It does this by considering runtime dependencies, resource requirements, and guiding policies for high availability, by spreading Pods horizontally, and also by colocating Pods nearby for performance and low-latency interactions. However, for the scheduler to do its job correctly and allow declarative placement, it needs nodes with available capacity, and containers with declared resource profiles and guiding policies in place. Letâ€™s look at each of these in more detail.</p><p>åœ¨å¾ˆé«˜çš„å±‚é¢ä¸Šæ¥è¯´ï¼ŒKubernetesè°ƒåº¦å™¨æ‰§è¡Œçš„ä¸»è¦æ“ä½œæ˜¯ä»APIæœåŠ¡å™¨ä¸­æ£€ç´¢æ¯ä¸ªæ–°åˆ›å»ºçš„Podå®šä¹‰ï¼Œå¹¶å°†å…¶åˆ†é…åˆ°èŠ‚ç‚¹ä¸Šã€‚å®ƒä¸ºæ¯ä¸ªPodæ‰¾åˆ°ä¸€ä¸ªåˆé€‚çš„èŠ‚ç‚¹ï¼ˆåªè¦æœ‰è¿™æ ·ä¸€ä¸ªèŠ‚ç‚¹ï¼‰ï¼Œæ— è®ºæ˜¯ç”¨äºåˆå§‹åº”ç”¨ç¨‹åºæ”¾ç½®ã€æ‰©å±•ï¼Œè¿˜æ˜¯å°†åº”ç”¨ç¨‹åºä»ä¸å¥åº·çš„èŠ‚ç‚¹ç§»åŠ¨åˆ°æ›´å¥åº·çš„èŠ‚ç‚¹ã€‚å®ƒé€šè¿‡è€ƒè™‘è¿è¡Œæ—¶ä¾èµ–å…³ç³»ã€èµ„æºéœ€æ±‚å’Œé«˜å¯ç”¨æ€§æŒ‡å¯¼ç­–ç•¥ã€æ°´å¹³åˆ†å¸ƒpodä»¥åŠå°†podé›†ä¸­åœ¨é™„è¿‘ä»¥å®ç°æ€§èƒ½å’Œä½å»¶è¿Ÿäº¤äº’æ¥å®ç°è¿™ä¸€ç‚¹ã€‚ä½†æ˜¯ï¼Œä¸ºäº†è®©è°ƒåº¦å™¨æ­£ç¡®åœ°æ‰§è¡Œå…¶å·¥ä½œå¹¶å…è®¸å£°æ˜å¼æ”¾ç½®ï¼Œå®ƒéœ€è¦å…·æœ‰å¯ç”¨å®¹é‡çš„èŠ‚ç‚¹ï¼Œä»¥åŠå…·æœ‰å£°æ˜çš„èµ„æºé…ç½®æ–‡ä»¶å’ŒæŒ‡å¯¼ç­–ç•¥çš„å®¹å™¨ã€‚è®©æˆ‘ä»¬æ›´è¯¦ç»†åœ°äº†è§£å…¶ä¸­çš„æ¯ä¸€é¡¹ã€‚</p><h4 id="_2-5-2-1-available-node-resources-å¯ç”¨èŠ‚ç‚¹èµ„æº" tabindex="-1"><a class="header-anchor" href="#_2-5-2-1-available-node-resources-å¯ç”¨èŠ‚ç‚¹èµ„æº" aria-hidden="true">#</a> 2.5.2.1 Available Node Resources Â  å¯ç”¨èŠ‚ç‚¹èµ„æº</h4><p>First of all, the Kubernetes cluster needs to have nodes with enough resource capacity to run new Pods. Every node has capacity available for running Pods, and the scheduler ensures that the sum of the resources requested for a Pod is less than the available allocatable node capacity. Considering a node dedicated only to Kubernetes, its capacity is calculated using the formula in Example 6-1.</p><p>é¦–å…ˆï¼ŒKubernetesé›†ç¾¤éœ€è¦å…·æœ‰è¶³å¤Ÿèµ„æºå®¹é‡çš„èŠ‚ç‚¹æ¥è¿è¡Œæ–°çš„PODã€‚æ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰è¿è¡ŒPodçš„å¯ç”¨å®¹é‡ï¼Œè°ƒåº¦å™¨ç¡®ä¿Podè¯·æ±‚çš„èµ„æºæ€»å’Œå°äºå¯ç”¨çš„å¯åˆ†é…èŠ‚ç‚¹å®¹é‡ã€‚è€ƒè™‘åˆ°ä»…ç”¨äºKubernetesçš„èŠ‚ç‚¹ï¼Œä½¿ç”¨ç¤ºä¾‹6-1ä¸­çš„å…¬å¼è®¡ç®—å…¶å®¹é‡ã€‚</p><p>Example 6-1. Node capacity</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>Allocatable [capacity for application pods] =
  Node Capacity [available capacity on a node]
    - Kube-Reserved [Kubernetes daemons like kubelet, container runtime]
    - System-Reserved [OS system daemons like sshd, udev]
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>If you donâ€™t reserve resources for system daemons that power the OS and Kubernetes itself, the Pods can be scheduled up to the full capacity of the node, which may cause Pods and system daemons to compete for resources, leading to resource starvation issues on the node. Also keep in mind that if containers are running on a node that is not managed by Kubernetes, the resources used by these containers are not reflected in the node capacity calculations by Kubernetes.</p><p>å¦‚æœä¸ç»™K8sç³»ç»Ÿæœ¬èº«å’Œé‚£äº›æ”¯æ’‘ç³»ç»Ÿçš„å®ˆæŠ¤è¿›ç¨‹é¢„ç•™ç³»ç»Ÿèµ„æºï¼Œåˆ™PODçš„è°ƒåº¦å¯èƒ½ä¼šè¾¾åˆ°èŠ‚ç‚¹çš„æœ€å¤§å®¹é‡ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´PODå’Œç³»ç»Ÿå®ˆæŠ¤è¿›ç¨‹äº‰å¤ºèµ„æºï¼Œä»è€Œå¯¼è‡´èŠ‚ç‚¹ä¸Šçš„èµ„æºä¸è¶³é—®é¢˜ã€‚è¿˜è¯·è®°ä½ï¼Œå¦‚æœå®¹å™¨è¿è¡Œåœ¨éKubernetesç®¡ç†çš„èŠ‚ç‚¹ä¸Šï¼Œè¿™äº›å®¹å™¨ä½¿ç”¨çš„èµ„æºä¸ä¼šåæ˜ åœ¨Kubernetesçš„èŠ‚ç‚¹å®¹é‡è®¡ç®—ä¸­ã€‚</p><p>A workaround for this limitation is to run a placeholder Pod that doesnâ€™t do anything, but has only resource requests for CPU and memory corresponding to the untracked containersâ€™ resource use amount. Such a Pod is created only to represent and reserve the resource consumption of the untracked containers and helps the scheduler build a better resource model of the node.</p><p>ä¸ºäº†è§£å†³ä¸Šé¢è¯´çš„è¿™ä¸ªé—®é¢˜ï¼Œå¯ç”¨é€šè¿‡è¿è¡Œä¸€ä¸ªå ä½ç¬¦Podæ¥å®ç°ï¼Œå®ƒä¸åšä»»ä½•äº‹æƒ…ï¼Œåªæ˜¯è¯·æ±‚ä¸é‚£äº›æœªè·Ÿè¸ªï¼ˆä¸å±äºK8sçš„ï¼‰å®¹å™¨èµ„æºä½¿ç”¨é‡ç›¸å¯¹åº”çš„CPUå’Œå†…å­˜çš„èµ„æºã€‚åˆ›å»ºè¿™æ ·çš„Podåªæ˜¯ä¸ºäº†è¡¨ç¤ºå’Œä¿ç•™æœªè·Ÿè¸ªå®¹å™¨çš„èµ„æºæ¶ˆè€—ï¼Œå¹¶å¸®åŠ©è°ƒåº¦å™¨æ„å»ºæ›´å¥½çš„èŠ‚ç‚¹èµ„æºæ¨¡å‹ã€‚</p><h4 id="_2-5-2-2-container-resource-demands-å®¹å™¨èµ„æºå£°æ˜" tabindex="-1"><a class="header-anchor" href="#_2-5-2-2-container-resource-demands-å®¹å™¨èµ„æºå£°æ˜" aria-hidden="true">#</a> 2.5.2.2 Container Resource Demands Â å®¹å™¨èµ„æºå£°æ˜</h4><p>Another important requirement for an efficient Pod placement is that containers have their runtime dependencies and resource demands defined. We covered that in more detail in Chapter 2, Predictable Demands. It boils down to having containers that declare their resource profiles (with request and limit) and environment dependencies such as storage or ports. Only then are Pods sensibly assigned to nodes and can run without affecting each other during peak times.</p><p>æœ‰æ•ˆæ”¾ç½®Podçš„å¦ä¸€ä¸ªé‡è¦è¦æ±‚ï¼Œæ˜¯å®¹å™¨å®šä¹‰äº†å…¶è¿è¡Œæ—¶ä¾èµ–é¡¹å’Œèµ„æºéœ€æ±‚ã€‚æˆ‘ä»¬åœ¨æœ¬ç« ç¬¬1èŠ‚â€œå¯é¢„æµ‹éœ€æ±‚â€ä¸­æ›´è¯¦ç»†åœ°ä»‹ç»äº†è¿™ä¸€ç‚¹ã€‚å®ƒå½’ç»“ä¸ºå…·æœ‰å£°æ˜å…¶èµ„æºé…ç½®æ–‡ä»¶ï¼ˆå¸¦æœ‰è¯·æ±‚å’Œé™åˆ¶ï¼‰å’Œç¯å¢ƒä¾èµ–é¡¹ï¼ˆå¦‚å­˜å‚¨æˆ–ç«¯å£ï¼‰çš„å®¹å™¨ã€‚åªæœ‰è¿™æ ·ï¼ŒPODæ‰èƒ½åˆç†åœ°åˆ†é…ç»™èŠ‚ç‚¹ï¼Œå¹¶ä¸”åœ¨é«˜å³°æ—¶é—´è¿è¡Œæ—¶ä¸ä¼šç›¸äº’å½±å“ã€‚</p><h4 id="_2-5-2-3-placement-policies-æ”¾ç½®ç­–ç•¥" tabindex="-1"><a class="header-anchor" href="#_2-5-2-3-placement-policies-æ”¾ç½®ç­–ç•¥" aria-hidden="true">#</a> 2.5.2.3 Placement Policies Â æ”¾ç½®ç­–ç•¥</h4><p>The last piece of the puzzle is having the right filtering or priority policies for your specific application needs. The scheduler has a default set of predicate and priority policies configured that is good enough for most use cases. It can be overridden during scheduler startup with a different set of policies, as shown in Example 6-2.</p><p>æœ€åä¸€ä¸ªéš¾é¢˜æ˜¯ä¸ºç‰¹å®šåº”ç”¨ç¨‹åºéœ€æ±‚åˆ¶å®šæ­£ç¡®çš„è¿‡æ»¤æˆ–ä¼˜å…ˆçº§ç­–ç•¥ã€‚è°ƒåº¦å™¨é…ç½®äº†ä¸€ç»„é»˜è®¤çš„è°“è¯å’Œä¼˜å…ˆçº§ç­–ç•¥ï¼Œå¯¹äºå¤§å¤šæ•°ç”¨ä¾‹æ¥è¯´å·²ç»è¶³å¤Ÿå¥½äº†ã€‚åœ¨è°ƒåº¦ç¨‹åºå¯åŠ¨æœŸé—´ï¼Œå¯ä»¥ä½¿ç”¨ä¸€ç»„ä¸åŒçš„ç­–ç•¥è¦†ç›–å®ƒï¼Œå¦‚ç¤ºä¾‹6-2æ‰€ç¤ºã€‚</p><p>Example 6-2. An example scheduler policy</p><div class="language-yaml line-numbers-mode" data-ext="yml"><pre class="language-yaml"><code><span class="token punctuation">{</span>
 <span class="token key atrule">&quot;kind&quot;</span> <span class="token punctuation">:</span> <span class="token string">&quot;Policy&quot;</span><span class="token punctuation">,</span>
 <span class="token key atrule">&quot;apiVersion&quot;</span> <span class="token punctuation">:</span> <span class="token string">&quot;v1&quot;</span><span class="token punctuation">,</span>
 <span class="token key atrule">&quot;predicates&quot;</span> <span class="token punctuation">:</span> <span class="token punctuation">[</span>
  <span class="token punctuation">{</span><span class="token key atrule">&quot;name&quot;</span> <span class="token punctuation">:</span> <span class="token string">&quot;PodFitsHostPorts&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span><span class="token key atrule">&quot;name&quot;</span> <span class="token punctuation">:</span> <span class="token string">&quot;PodFitsResources&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span><span class="token key atrule">&quot;name&quot;</span> <span class="token punctuation">:</span> <span class="token string">&quot;NoDiskConflict&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span><span class="token key atrule">&quot;name&quot;</span> <span class="token punctuation">:</span> <span class="token string">&quot;NoVolumeZoneConflict&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span><span class="token key atrule">&quot;name&quot;</span> <span class="token punctuation">:</span> <span class="token string">&quot;MatchNodeSelector&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span><span class="token key atrule">&quot;name&quot;</span> <span class="token punctuation">:</span> <span class="token string">&quot;HostName&quot;</span><span class="token punctuation">}</span>
 <span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token key atrule">&quot;priorities&quot;</span> <span class="token punctuation">:</span> <span class="token punctuation">[</span>
  <span class="token punctuation">{</span><span class="token key atrule">&quot;name&quot;</span> <span class="token punctuation">:</span> <span class="token string">&quot;LeastRequestedPriority&quot;</span><span class="token punctuation">,</span> <span class="token key atrule">&quot;weight&quot;</span> <span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span><span class="token key atrule">&quot;name&quot;</span> <span class="token punctuation">:</span> <span class="token string">&quot;BalancedResourceAllocation&quot;</span><span class="token punctuation">,</span> <span class="token key atrule">&quot;weight&quot;</span> <span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span><span class="token key atrule">&quot;name&quot;</span> <span class="token punctuation">:</span> <span class="token string">&quot;ServiceSpreadingPriority&quot;</span><span class="token punctuation">,</span> <span class="token key atrule">&quot;weight&quot;</span> <span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span><span class="token key atrule">&quot;name&quot;</span> <span class="token punctuation">:</span> <span class="token string">&quot;EqualPriority&quot;</span><span class="token punctuation">,</span> <span class="token key atrule">&quot;weight&quot;</span> <span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span>
 <span class="token punctuation">]</span>
<span class="token punctuation">}</span>
<span class="token comment">#Predicates are rules that filter out unqualified nodes. For example, PodFitsHostsPorts schedules Pods to request certain fixed host ports only on those nodes that have this port still available.</span>
<span class="token comment">#Predicatesæ˜¯è¿‡æ»¤å‡ºé‚£äº›ä¸ç¬¦åˆçš„èŠ‚ç‚¹çš„è§„åˆ™ã€‚ä¾‹å¦‚ï¼ŒPodFitsHostsPortså°†è¯·æ±‚æŸäº›å›ºå®šä¸»æœºç«¯å£çš„podè°ƒåº¦åˆ°é‚£äº›ä»æœ‰æ­¤ç«¯å£å¯ç”¨çš„èŠ‚ç‚¹ä¸Šã€‚</span>
<span class="token comment">#Priorities are rules that sort available nodes according to preferences. For example, LeastRequestedPriority gives nodes with fewer requested resources a higher priority.</span>
<span class="token comment">#Prioritiesæ˜¯æ ¹æ®è¡¨ç°å¯¹å¯ç”¨èŠ‚ç‚¹æ’åºçš„è§„åˆ™ã€‚ä¾‹å¦‚ï¼ŒLeastRequestedPriorityä¸ºè¯·æ±‚èµ„æºè¾ƒå°‘çš„èŠ‚ç‚¹æä¾›äº†æ›´é«˜çš„ä¼˜å…ˆçº§ã€‚</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>Scheduler policies and custom schedulers can be defined only by an administrator as part of the cluster configuration. As a regular user you just can refer to predefined schedulers.</p><p>ä½œä¸ºç¾¤é›†é…ç½®çš„ä¸€éƒ¨åˆ†ï¼Œè°ƒåº¦å™¨ç­–ç•¥å’Œè‡ªå®šä¹‰è°ƒåº¦å™¨åªèƒ½ç”±ç®¡ç†å‘˜è¿›è¡Œå®šä¹‰ã€‚ä½œä¸ºæ™®é€šç”¨æˆ·ï¼Œåªéœ€å‚è€ƒé¢„å®šä¹‰çš„è°ƒåº¦ç¨‹åºå³å¯ã€‚</p></blockquote><p>Consider that in addition to configuring the policies of the default scheduler, it is also possible to run multiple schedulers and allow Pods to specify which scheduler to place them. You can start another scheduler instance that is configured differently by giving it a unique name. Then when defining a Pod, just add the field .spec.schedulerName with the name of your custom scheduler to the Pod specification and the Pod will be picked up by the custom scheduler only.</p><p>è€ƒè™‘åˆ°é™¤äº†é…ç½®é»˜è®¤è°ƒåº¦å™¨çš„ç­–ç•¥å¤–ï¼Œè¿˜å¯ä»¥è¿è¡Œå¤šä¸ªè°ƒåº¦å™¨ï¼Œå¹¶å…è®¸PODæŒ‡å®šæ”¾ç½®å®ƒä»¬çš„è°ƒåº¦å™¨ã€‚å¯ä»¥é€šè¿‡ä¸åŒçš„å‘½åæ¥å¯åŠ¨å¦ä¸€ä¸ªé…ç½®ä¸åŒçš„è°ƒåº¦ç¨‹åºå®ä¾‹ã€‚ç„¶ååœ¨å®šä¹‰Podæ—¶ï¼Œåªéœ€å°†å¸¦æœ‰è‡ªå®šä¹‰è°ƒåº¦ç¨‹åºåç§°çš„.spec.schedulerNameå­—æ®µæ·»åŠ åˆ°Podè§„èŒƒä¸­ï¼ŒPodå°†ä»…ç”±è‡ªå®šä¹‰è°ƒåº¦ç¨‹åºæ‹¾å–ã€‚</p><h4 id="_2-5-2-4-scheduling-process-è°ƒåº¦è¿›ç¨‹" tabindex="-1"><a class="header-anchor" href="#_2-5-2-4-scheduling-process-è°ƒåº¦è¿›ç¨‹" aria-hidden="true">#</a> 2.5.2.4 Scheduling Process Â è°ƒåº¦è¿›ç¨‹</h4><p>Pods get assigned to nodes with certain capacities based on placement policies. For completeness, Figure 6-1 visualizes at a high level how these elements get together and the main steps a Pod goes through when being scheduled.</p><p>PODæ ¹æ®æ”¾ç½®ç­–ç•¥åˆ†é…ç»™å…·æœ‰ç‰¹å®šå®¹é‡çš„èŠ‚ç‚¹ã€‚ä¸ºäº†å®Œæ•´èµ·è§ï¼Œå›¾6-1ä»è¾ƒé«˜çš„å±‚æ¬¡ä¸Šå±•ç¤ºäº†è¿™äº›å…ƒç´ æ˜¯å¦‚ä½•ç»„åˆåœ¨ä¸€èµ·çš„ï¼Œä»¥åŠPodåœ¨è°ƒåº¦æ—¶æ‰€ç»å†çš„ä¸»è¦æ­¥éª¤ã€‚</p><figure><img src="https://cdn.nlark.com/yuque/0/2021/png/2466332/1636032081854-a1558479-743a-4f92-a683-7c2668d0a144.png#clientId=u0d4ab37c-7ab2-4&amp;from=paste&amp;height=924&amp;id=u68ad5bba&amp;margin=[object Object]&amp;name=image.png&amp;originHeight=924&amp;originWidth=1195&amp;originalType=binary&amp;ratio=1&amp;size=148957&amp;status=done&amp;style=none&amp;taskId=u73f042da-6d31-4f24-8073-fdce3134e8c&amp;width=1195" alt="image.png" tabindex="0" loading="lazy"><figcaption>image.png</figcaption></figure><p>Figure 6-1. A Pod-to-node assignment process</p><p>As soon as a Pod is created that is not assigned to a node yet, it gets picked by the scheduler together with all the available nodes and the set of filtering and priority policies. In the first stage, the scheduler applies the filtering policies and removes all nodes that do not qualify based on the Podâ€™s criteria. In the second stage, the remainâ€ing nodes get ordered by weight. In the last stage the Pod gets a node assigned, which is the primary outcome of the cheduling process.</p><p>ä¸€æ—¦åˆ›å»ºäº†ä¸€ä¸ªå°šæœªåˆ†é…ç»™èŠ‚ç‚¹çš„Podï¼Œè°ƒåº¦ç¨‹åºå°±ä¼šå°†å…¶ä¸æ‰€æœ‰å¯ç”¨èŠ‚ç‚¹ä»¥åŠä¸€ç»„ç­›é€‰å’Œä¼˜å…ˆçº§ç­–ç•¥ä¸€èµ·æ‹¾å–ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œè°ƒåº¦å™¨åº”ç”¨è¿‡æ»¤ç­–ç•¥ï¼Œå¹¶æ ¹æ®Podçš„æ ‡å‡†åˆ é™¤æ‰€æœ‰ä¸ç¬¦åˆæ¡ä»¶çš„èŠ‚ç‚¹ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œå‰©ä½™èŠ‚ç‚¹æŒ‰æƒé‡æ’åºã€‚åœ¨æœ€åä¸€ä¸ªé˜¶æ®µï¼ŒPodè·å¾—åˆ†é…çš„èŠ‚ç‚¹ï¼Œè¿™æ˜¯è°ƒåº¦è¿‡ç¨‹çš„ä¸»è¦ç»“æœã€‚</p><p>In most cases, it is better to let the scheduler do the Pod-to-node assignment and not micromanage the placement logic. However, on some occasions, you may want to force the assignment of a Pod to a specific node or a group of nodes. This assignment can be done using a node selector. .spec.nodeSelector is Pod field and specifies a map of key-value pairs that must be present as labels on the node for the node to be eligible to run the Pod. For example, say you want to force a Pod to run on a specific node where you have SSD storage or GPU acceleration hardware. With the Pod definition in Example 6-3 that has nodeSelector matching disktype: ssd, only nodes that are labeled with disktype=ssd will be eligible to run the Pod.</p><p>åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæœ€å¥½è®©è°ƒåº¦å™¨æ‰§è¡ŒPodåˆ°èŠ‚ç‚¹çš„åˆ†é…ï¼Œè€Œä¸æ˜¯å¾®è§‚ç®¡ç†æ”¾ç½®é€»è¾‘ã€‚ä½†æ˜¯ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¯èƒ½å¸Œæœ›å¼ºåˆ¶å°†Podåˆ†é…ç»™ç‰¹å®šèŠ‚ç‚¹æˆ–ä¸€ç»„èŠ‚ç‚¹ã€‚å¯ä»¥ä½¿ç”¨èŠ‚ç‚¹é€‰æ‹©å™¨å®Œæˆæ­¤åˆ†é…ã€‚spec.nodeSelectoræ˜¯Podå­—æ®µï¼ŒæŒ‡å®šäº†ä¸€ç»„é”®å€¼å¯¹ï¼Œåªæœ‰æ ‡è®°äº†æ»¡è¶³é”®å€¼å¯¹ä¸­æ¡ä»¶çš„èŠ‚ç‚¹ï¼Œæ‰æœ‰èµ„æ ¼è¿è¡Œè¿™äº›Podã€‚ä¾‹å¦‚ï¼Œå‡è®¾ä½ å¸Œæœ›å¼ºåˆ¶Podåœ¨å…·æœ‰SSDå­˜å‚¨æˆ–GPUåŠ é€Ÿç¡¬ä»¶çš„ç‰¹å®šèŠ‚ç‚¹ä¸Šè¿è¡Œã€‚å¯¹äºç¤ºä¾‹6-3ä¸­å…·æœ‰èŠ‚ç‚¹é€‰æ‹©å™¨åŒ¹é…disktype:ssdçš„Podå®šä¹‰ï¼Œåªæœ‰æ ‡è®°ä¸ºdisktype=ssdçš„èŠ‚ç‚¹æ‰æœ‰èµ„æ ¼è¿è¡ŒPodã€‚</p><p>Example 6-3. Node selector based on type of disk available</p><div class="language-yaml line-numbers-mode" data-ext="yml"><pre class="language-yaml"><code><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> Pod
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> random<span class="token punctuation">-</span>generator
<span class="token key atrule">spec</span><span class="token punctuation">:</span>
  <span class="token key atrule">containers</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token key atrule">image</span><span class="token punctuation">:</span> k8spatterns/random<span class="token punctuation">-</span>generator<span class="token punctuation">:</span><span class="token number">1.0</span>
    <span class="token key atrule">name</span><span class="token punctuation">:</span> random<span class="token punctuation">-</span>generator
  <span class="token key atrule">nodeSelector</span><span class="token punctuation">:</span>
    <span class="token key atrule">disktype</span><span class="token punctuation">:</span> ssd
<span class="token comment">#Set of node labels a node must match to be considered to be the node of this Pod</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>In addition to specifying custom labels to your nodes, you can use some of the default labels that are present on every node. Every node has a unique <a href="http://kubernetes.io/host" target="_blank" rel="noopener noreferrer">kubernetes.io/host<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> name label that can be used to place a Pod on a node by its hostname. Other default labels that indicate the OS, architecture, and instance-type can be useful for placement too.</p><p>é™¤äº†ä¸ºèŠ‚ç‚¹æŒ‡å®šè‡ªå®šä¹‰æ ‡ç­¾å¤–ï¼Œè¿˜å¯ä»¥ä½¿ç”¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šå­˜åœ¨çš„ä¸€äº›é»˜è®¤æ ‡ç­¾ã€‚<a href="http://xn--kubernetes-pf2pa85cb960ycj9dr7q9guhfzdf7cit9c.io/host" target="_blank" rel="noopener noreferrer">æ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰ä¸€ä¸ªå”¯ä¸€çš„kubernetes.io/host<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> nameæ ‡ç­¾ï¼Œå¯ç”¨äºæ ¹æ®å…¶ä¸»æœºååœ¨èŠ‚ç‚¹ä¸Šæ”¾ç½®Podã€‚æŒ‡ç¤ºæ“ä½œç³»ç»Ÿã€ä½“ç³»ç»“æ„å’Œå®ä¾‹ç±»å‹çš„å…¶ä»–é»˜è®¤æ ‡ç­¾å¯¹äºæ”¾ç½®Podä¹Ÿæ˜¯å¾ˆæœ‰ç”¨çš„ã€‚</p><h4 id="_2-5-2-5-node-affinity-èŠ‚ç‚¹å…³è”-äº²å’Œæ€§" tabindex="-1"><a class="header-anchor" href="#_2-5-2-5-node-affinity-èŠ‚ç‚¹å…³è”-äº²å’Œæ€§" aria-hidden="true">#</a> 2.5.2.5 Node Affinity Â èŠ‚ç‚¹å…³è”(äº²å’Œæ€§)</h4><p>Kubernetes supports many more flexible ways to configure the scheduling processes.One such a feature is node affinity, which is a generalization of the node selector approach described previously that allows specifying rules as either required or preferred. Required rules must be met for a Pod to be scheduled to a node, whereas preferred rules only imply preference by increasing the weight for the matching nodes without making them mandatory. Besides, the node affinity feature greatly expands the types of constraints you can express by making the language more expressive with operators such as In, NotIn, Exists, DoesNotExist, Gt, or Lt. Example 6-4 demonstrates how node affinity is declared.</p><p>Kubernetesæ”¯æŒè®¸å¤šæ›´çµæ´»çš„æ–¹å¼æ¥é…ç½®è°ƒåº¦è¿‡ç¨‹ã€‚å…¶ä¸­ä¸€ä¸ªåŠŸèƒ½æ˜¯èŠ‚ç‚¹å…³è”ï¼Œå®ƒæ˜¯å‰é¢æè¿°çš„èŠ‚ç‚¹é€‰æ‹©å™¨æ–¹æ³•çš„æ³›åŒ–ï¼Œå…è®¸æ ¹æ®éœ€è¦æˆ–é¦–é€‰æŒ‡å®šè§„åˆ™ã€‚Podè°ƒåº¦åˆ°èŠ‚ç‚¹æ—¶å¿…é¡»æ»¡è¶³æ‰€éœ€çš„è§„åˆ™ï¼Œè€Œé¦–é€‰è§„åˆ™ä»…é€šè¿‡å¢åŠ åŒ¹é…èŠ‚ç‚¹çš„æƒé‡æ¥æš—ç¤ºåå¥½ï¼Œè€Œä¸å¼ºåˆ¶è¦æ±‚å®ƒä»¬ã€‚æ­¤å¤–ï¼ŒèŠ‚ç‚¹å…³è”åŠŸèƒ½é€šè¿‡ä½¿ç”¨è¯¸å¦‚Inã€NotInã€Existsã€DOESNOTEXTISTã€Gtæˆ–Ltç­‰è¿ç®—ç¬¦ä½¿è¯­è¨€æ›´å…·è¡¨ç°åŠ›ï¼Œä»è€Œå¤§å¤§æ‰©å±•äº†å¯ä»¥è¡¨è¾¾çš„çº¦æŸç±»å‹ã€‚ç¤ºä¾‹6-4æ¼”ç¤ºäº†å¦‚ä½•å£°æ˜èŠ‚ç‚¹å…³è”ã€‚</p><p>Example 6-4. Pod with node affinity</p><div class="language-yaml line-numbers-mode" data-ext="yml"><pre class="language-yaml"><code><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> Pod
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> random<span class="token punctuation">-</span>generator
<span class="token key atrule">spec</span><span class="token punctuation">:</span>
  <span class="token key atrule">affinity</span><span class="token punctuation">:</span>
    <span class="token key atrule">nodeAffinity</span><span class="token punctuation">:</span>
      <span class="token key atrule">requiredDuringSchedulingIgnoredDuringExecution</span><span class="token punctuation">:</span>
      <span class="token comment">#Hard requirement that the node must have more than three cores (indicated by a node label) to be considered in the scheduling process. The rule is not reevaluated during execution if the conditions on the node change.</span>
      <span class="token key atrule">nodeSelectorTerms</span><span class="token punctuation">:</span>
      <span class="token comment">#Match on labels. In this example all nodes are matched that have a label number Cores with a value greater than 3.</span>
      <span class="token punctuation">-</span> <span class="token key atrule">matchExpressions</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">key</span><span class="token punctuation">:</span> numberCores
          <span class="token key atrule">operator</span><span class="token punctuation">:</span> Gt
          <span class="token key atrule">values</span><span class="token punctuation">:</span> <span class="token punctuation">[</span> <span class="token string">&quot;3&quot;</span> <span class="token punctuation">]</span>
      <span class="token key atrule">preferredDuringSchedulingIgnoredDuringExecution</span><span class="token punctuation">:</span>
      <span class="token comment">#Soft requirements, which is a list of selectors with weights. For every node, the sum of all weights for matching selectors is calculated, and the highest-valued node is chosen, as long as it matches the hard requirement.</span>
      <span class="token punctuation">-</span> <span class="token key atrule">weight</span><span class="token punctuation">:</span> <span class="token number">1</span>
        <span class="token key atrule">preference</span><span class="token punctuation">:</span>
          <span class="token key atrule">matchFields</span><span class="token punctuation">:</span>
          <span class="token comment">#Match on a field (specified as jsonpath). Note that only In and NotIn are allowed as operators, and only one value is allowed to be given in the list of values.</span>
          <span class="token punctuation">-</span> <span class="token key atrule">key</span><span class="token punctuation">:</span> metadata.name
            <span class="token key atrule">operator</span><span class="token punctuation">:</span> NotIn
            <span class="token key atrule">values</span><span class="token punctuation">:</span> <span class="token punctuation">[</span> <span class="token string">&quot;master&quot;</span> <span class="token punctuation">]</span>
<span class="token key atrule">containers</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> <span class="token key atrule">image</span><span class="token punctuation">:</span> k8spatterns/random<span class="token punctuation">-</span>generator<span class="token punctuation">:</span><span class="token number">1.0</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> random<span class="token punctuation">-</span>generator
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_2-5-2-6-pod-affinity-and-antiaffinity-podå…³è”-äº²å’Œ-ä¸åå…³è”-ä¸ºäº†ä¿æŒå’Œnode-affinity-ä¸€è‡´" tabindex="-1"><a class="header-anchor" href="#_2-5-2-6-pod-affinity-and-antiaffinity-podå…³è”-äº²å’Œ-ä¸åå…³è”-ä¸ºäº†ä¿æŒå’Œnode-affinity-ä¸€è‡´" aria-hidden="true">#</a> 2.5.2.6 Pod Affinity and Antiaffinity Â  Podå…³è”ï¼ˆäº²å’Œï¼‰ä¸åå…³è”ï¼ˆä¸ºäº†ä¿æŒå’ŒNode Affinity ä¸€è‡´ï¼‰</h4><p>Node affinity is a more powerful way of scheduling and should be preferred when <code>nodeSelector</code> is not enough. This mechanism allows constraining which nodes a Pod can run based on label or field matching. It doesnâ€™t allow expressing dependencies among Pods to dictate where a Pod should be placed relative to other Pods. To express how Pods should be spread to achieve high availability, or be packed and colocated together to improve latency, Pod affinity and antiaffinity can be used.</p><p>èŠ‚ç‚¹å…³è”æ˜¯ä¸€ç§æ›´å¼ºå¤§çš„è°ƒåº¦æ–¹å¼ï¼Œå½“<code>nodeSelector</code>ä¸å¤Ÿç”¨æ—¶ï¼Œåº”è¯¥ä¼˜å…ˆä½¿ç”¨ã€‚è¯¥æœºåˆ¶å…è®¸åŸºäºæ ‡ç­¾æˆ–å­—æ®µåŒ¹é…æ¥çº¦æŸPodå¯ä»¥è¿è¡Œçš„èŠ‚ç‚¹ã€‚å®ƒä¸å…è®¸è¡¨è¾¾Podä¹‹é—´çš„ä¾èµ–å…³ç³»æ¥å†³å®šä¸€ä¸ªPodç›¸å¯¹äºå…¶ä»–Podåº”è¯¥æ”¾ç½®åœ¨å“ªé‡Œã€‚ä¸ºäº†è¯´æ˜Podåº”è¯¥å¦‚ä½•ä¼ æ’­ä»¥å®ç°é«˜å¯ç”¨æ€§ï¼Œæˆ–è€…å¦‚ä½•æ‰“åŒ…å¹¶å…±åŒæ”¾ç½®ä»¥æé«˜å»¶è¿Ÿï¼Œå¯ä»¥ä½¿ç”¨Podå…³è”å’Œåå…³è”çš„æ–¹æ³•ã€‚</p><p>Node affinity works at node granularity, but Pod affinity is not limited to nodes and can express rules at multiple topology levels. Using the topologyKey field, and the matching labels, it is possible to enforce more fine-grained rules, which combine rules on domains like node, rack, cloud provider zone, and region, as demonstrated in Example 6-5.</p><p>èŠ‚ç‚¹å…³è”åœ¨èŠ‚ç‚¹ç²’åº¦ä¸Šå·¥ä½œï¼Œä½†Podå…³è”ä¸é™äºèŠ‚ç‚¹ï¼Œå¯ä»¥åœ¨å¤šä¸ªæ‹“æ‰‘çº§åˆ«ä¸Šè¡¨è¾¾è§„åˆ™ã€‚ä½¿ç”¨topologyKeyå­—æ®µå’ŒåŒ¹é…æ ‡ç­¾ï¼Œå¯ä»¥å®æ–½æ›´ç»†ç²’åº¦çš„è§„åˆ™ï¼Œè¿™äº›è§„åˆ™ç»“åˆäº†èŠ‚ç‚¹ã€æ¶æ„ã€äº‘åŸç”Ÿå¹³å°ä¸­çš„åŒºåŸŸå’Œé¢†åŸŸç­‰åŸŸä¸Šçš„è§„åˆ™ï¼Œå¦‚ç¤ºä¾‹6-5æ‰€ç¤ºã€‚</p><p>Example 6-5. Pod with Pod affinity</p><div class="language-yaml line-numbers-mode" data-ext="yml"><pre class="language-yaml"><code><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> Pod
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
 <span class="token key atrule">name</span><span class="token punctuation">:</span> random<span class="token punctuation">-</span>generator
<span class="token key atrule">spec</span><span class="token punctuation">:</span>
 <span class="token key atrule">affinity</span><span class="token punctuation">:</span>
  <span class="token key atrule">podAffinity</span><span class="token punctuation">:</span>
   <span class="token key atrule">requiredDuringSchedulingIgnoredDuringExecution</span><span class="token punctuation">:</span>
   <span class="token punctuation">-</span> <span class="token key atrule">labelSelector</span><span class="token punctuation">:</span>
    <span class="token key atrule">matchLabels</span><span class="token punctuation">:</span>
     <span class="token key atrule">confidential</span><span class="token punctuation">:</span> high
    <span class="token key atrule">topologyKey</span><span class="token punctuation">:</span> security<span class="token punctuation">-</span>zone
   <span class="token key atrule">podAntiAffinity</span><span class="token punctuation">:</span>
    <span class="token key atrule">preferredDuringSchedulingIgnoredDuringExecution</span><span class="token punctuation">:</span>
    <span class="token punctuation">-</span> <span class="token key atrule">weight</span><span class="token punctuation">:</span> <span class="token number">100</span>
     <span class="token key atrule">podAffinityTerm</span><span class="token punctuation">:</span>
      <span class="token key atrule">labelSelector</span><span class="token punctuation">:</span>
       <span class="token key atrule">matchLabels</span><span class="token punctuation">:</span>
        <span class="token key atrule">confidential</span><span class="token punctuation">:</span> none
       <span class="token key atrule">topologyKey</span><span class="token punctuation">:</span> kubernetes.io/hostname
   <span class="token key atrule">containers</span><span class="token punctuation">:</span>
   <span class="token punctuation">-</span> <span class="token key atrule">image</span><span class="token punctuation">:</span> k8spatterns/random<span class="token punctuation">-</span>generator<span class="token punctuation">:</span><span class="token number">1.0</span>
    <span class="token key atrule">name</span><span class="token punctuation">:</span> random<span class="token punctuation">-</span>generator
<span class="token comment">#Required rules for the Pod placement concerning other Pods running on the target node.</span>
<span class="token comment">#Label selector to find the Pods to be colocated with.</span>
<span class="token comment">#The nodes on which Pods with labels confidential=high are running are supposed to carry a label security-zone. The Pod defined here is scheduled to a node with the same label and value.</span>
<span class="token comment">#Antiaffinity rules to find nodes where a Pod would not be placed.</span>
<span class="token comment">#Rule describing that the Pod should not (but could) be placed on any node where a Pod with the label confidential=none is running.</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Similar to node affinity, there are hard and soft requirements for Pod affinity and antiaffinity, called <code>requiredDuringSchedulingIgnoredDuringExecution</code> and <code>preferredDuringSchedulingIgnoredDuringExecution</code>, respectively. Again, as with node affinity, there is the <code>IgnoredDuringExecution</code> suffix in the field name, which exists for future extensibility reasons. At the moment, if the labels on the node change and affinity rules are no longer valid, the Pods continue running, but in the future runtime changes may also be taken into account.</p><p>ä¸èŠ‚ç‚¹å…³è”ç±»ä¼¼ï¼ŒPodå…³è”å’Œåå…³è”æ€§ä¹Ÿæœ‰ç¡¬éœ€æ±‚å’Œè½¯éœ€æ±‚ï¼Œåˆ†åˆ«ç§°ä¸º_requiredDuringSchedulingIgnoredDuringExecution_å’Œ_PreferredDuringSchedulingIgnoredDuringExecution_ã€‚åŒæ ·ï¼Œä¸èŠ‚ç‚¹å…³è”ä¸€æ ·ï¼Œå­—æ®µåä¸­ä¹Ÿæœ‰_IgnoredDuringExecution_åç¼€ï¼Œå®ƒçš„å­˜åœ¨æ˜¯ä¸ºäº†å°†æ¥çš„æ‰©å±•æ€§ã€‚æ­¤æ—¶ï¼Œå¦‚æœèŠ‚ç‚¹ä¸Šçš„æ ‡ç­¾æ›´æ”¹ï¼Œå¹¶ä¸”å…³è”è§„åˆ™ä¸å†æœ‰æ•ˆï¼Œåˆ™PODå°†ç»§ç»­è¿è¡Œï¼Œä½†åœ¨å°†æ¥çš„è¿è¡Œæ—¶ï¼Œä¹Ÿå¯èƒ½ä¼šè€ƒè™‘æ›´æ”¹ã€‚</p><h4 id="_2-5-2-7-taints-and-tolerations-æ±¡ç‚¹-å…·ä½“æ˜¯æŒ‡èŠ‚ç‚¹çš„ç‰¹å¾-æ„Ÿè§‰æ˜¯ä¸ªæ ‡ç­¾ä¸€æ ·çš„-å’Œå®¹å¿" tabindex="-1"><a class="header-anchor" href="#_2-5-2-7-taints-and-tolerations-æ±¡ç‚¹-å…·ä½“æ˜¯æŒ‡èŠ‚ç‚¹çš„ç‰¹å¾-æ„Ÿè§‰æ˜¯ä¸ªæ ‡ç­¾ä¸€æ ·çš„-å’Œå®¹å¿" aria-hidden="true">#</a> 2.5.2.7 Taints and Tolerations Â  Â æ±¡ç‚¹ï¼ˆå…·ä½“æ˜¯æŒ‡èŠ‚ç‚¹çš„ç‰¹å¾ï¼Œæ„Ÿè§‰æ˜¯ä¸ªæ ‡ç­¾ä¸€æ ·çš„ï¼‰å’Œå®¹å¿</h4><p>A more advanced feature that controls where Pods can be scheduled and are allowed to run is based on taints and tolerations. While node affinity is a property of Pods that allows them to choose nodes, taints and tolerations are the opposite. They allow the nodes to control which Pods should or should not be scheduled on them. A taint is a characteristic of the node, and when it is present, it prevents Pods from scheduling onto the node unless the Pod has toleration for the taint. In that sense, taints and tolerations can be considered as an opt-in to allow scheduling on nodes, which by default are not available for scheduling, whereas affinity rules are an opt-out by explicitly selecting on which nodes to run and thus exclude all the nonselected nodes.</p><p>ä¸€ä¸ªæ›´é«˜çº§çš„ç‰¹æ€§æ˜¯åŸºäºæ±¡ç‚¹å’Œå®¹å¿åº¦æ¥æ§åˆ¶PODå¯ä»¥è°ƒåº¦å’Œå…è®¸è¿è¡Œçš„ä½ç½®ã€‚èŠ‚ç‚¹äº²å’ŒåŠ›ï¼ˆå…³è”ï¼‰æ˜¯PODçš„ä¸€ä¸ªå±æ€§ï¼Œå…è®¸å®ƒä»¬é€‰æ‹©èŠ‚ç‚¹ï¼Œè€Œæ±¡ç‚¹å’Œå®¹å¿åˆ™ç›¸åã€‚å®ƒä»¬å…è®¸èŠ‚ç‚¹æ§åˆ¶åº”è¯¥æˆ–ä¸åº”è¯¥åœ¨å…¶ä¸Šè°ƒåº¦å“ªäº›Podã€‚æ±¡ç‚¹æ˜¯èŠ‚ç‚¹çš„ä¸€ä¸ªç‰¹å¾ï¼Œå½“å®ƒå­˜åœ¨æ—¶ï¼Œå®ƒä¼šé˜»æ­¢Podè°ƒåº¦åˆ°èŠ‚ç‚¹ä¸Šï¼Œé™¤éPodå®¹å¿æ±¡ç‚¹ã€‚ä»è¿™ä¸ªæ„ä¹‰ä¸Šè®²ï¼Œæ±¡ç‚¹å’Œå®¹å¿å¯ä»¥è¢«è§†ä¸ºä¸€ç§é€‰æ‹©åŠ å…¥ï¼Œå…è®¸åœ¨èŠ‚ç‚¹ä¸Šè¿›è¡Œè°ƒåº¦ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œè¿™äº›èŠ‚ç‚¹ä¸å¯ç”¨äºè°ƒåº¦ï¼Œè€Œå…³è”è§„åˆ™åˆ™æ˜¯ä¸€ç§é€‰æ‹©é€€å‡ºï¼Œé€šè¿‡æ˜¾å¼é€‰æ‹©åœ¨å“ªäº›èŠ‚ç‚¹ä¸Šè¿è¡Œï¼Œä»è€Œæ’é™¤æ‰€æœ‰æœªé€‰æ‹©çš„èŠ‚ç‚¹ã€‚</p><p>A taint is added to a node by using kubectl: <code>kubectl taint nodes master noderole.kubernetes.io/master=&quot;true&quot;:NoSchedule</code>, which has the effect shown in Example 6-6. A matching toleration is added to a Pod as shown in Example 6-7. Notice that the values for key and effect in the taints section of Example 6-6 and the tolerations: section in Example 6-7 have the same values.</p><p>é€šè¿‡ä½¿ç”¨kubectl:<code>kubectl-taint-nodes-master noderole.kubernetes.io/master=â€œtrueâ€ï¼šNoSchedule</code>ï¼Œå¯ä»¥å°†æ±¡ç‚¹æ·»åŠ åˆ°èŠ‚ç‚¹ä¸­ï¼Œå…¶æ•ˆæœå¦‚ç¤ºä¾‹6-6æ‰€ç¤ºã€‚å¦‚ä¾‹6-7æ‰€ç¤ºï¼Œå°†å®¹å¿æ·»åŠ åˆ°Podä¸­ã€‚è¯·æ³¨æ„ï¼Œç¤ºä¾‹6-6çš„â€œæ±¡ç‚¹â€éƒ¨åˆ†ä¸­çš„â€œå…³é”®ç‚¹â€å’Œâ€œæ•ˆæœâ€çš„å€¼ä¸ç¤ºä¾‹6-7ä¸­çš„â€œå®¹å¿ï¼šéƒ¨åˆ†â€çš„å€¼ç›¸åŒã€‚</p><p>Example 6-6. Tainted node</p><div class="language-yaml line-numbers-mode" data-ext="yml"><pre class="language-yaml"><code><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> Node
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
 <span class="token key atrule">name</span><span class="token punctuation">:</span> master
<span class="token key atrule">spec</span><span class="token punctuation">:</span>
 <span class="token key atrule">taints</span><span class="token punctuation">:</span>
 <span class="token punctuation">-</span> <span class="token key atrule">effect</span><span class="token punctuation">:</span> NoSchedule
  <span class="token key atrule">key</span><span class="token punctuation">:</span> node<span class="token punctuation">-</span>role.kubernetes.io/master
<span class="token comment">#Taint on a nodeâ€™s spec to mark this node as not available for scheduling except when a Pod tolerates this taint</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Example 6-7. Pod tolerating node taints</p><div class="language-yaml line-numbers-mode" data-ext="yml"><pre class="language-yaml"><code><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> Pod
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
<span class="token key atrule">name</span><span class="token punctuation">:</span> random<span class="token punctuation">-</span>generator
<span class="token key atrule">spec</span><span class="token punctuation">:</span>
<span class="token key atrule">containers</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> <span class="token key atrule">image</span><span class="token punctuation">:</span> k8spatterns/random<span class="token punctuation">-</span>generator<span class="token punctuation">:</span><span class="token number">1.0</span>
<span class="token key atrule">name</span><span class="token punctuation">:</span> random<span class="token punctuation">-</span>generator
<span class="token key atrule">tolerations</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> <span class="token key atrule">key</span><span class="token punctuation">:</span> node<span class="token punctuation">-</span>role.kubernetes.io/master
<span class="token key atrule">operator</span><span class="token punctuation">:</span> Exists
<span class="token key atrule">effect</span><span class="token punctuation">:</span> NoSchedule
<span class="token comment">#Tolerate (i.e., consider for scheduling) nodes, which have a taint with key noderole. kubernetes.io/master. On production clusters, this taint is set on the master node to prevent scheduling of Pods on the master. A toleration like this allows this Pod to be installed on the master nevertheless.</span>
<span class="token comment">#Tolerate only when the taint specifies a NoSchedule effect. This field can be empty here, in which case the toleration applies to every effect.</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>There are hard taints that prevent scheduling on a node (effect=NoSchedule), soft taints that try to avoid scheduling on a node (effect=PreferNoSchedule), and taints that can evict already running Pods from a node (effect=NoExecute).</p><p>å­˜åœ¨é˜»æ­¢åœ¨èŠ‚ç‚¹ä¸Šè°ƒåº¦çš„ç¡¬æ±¡ç‚¹ï¼ˆeffect=NoScheduleï¼‰ï¼Œå°è¯•é¿å…åœ¨èŠ‚ç‚¹ä¸Šè°ƒåº¦çš„è½¯æ±¡ç‚¹ï¼ˆeffect=PreferNoScheduleï¼‰ï¼Œä»¥åŠå¯ä»¥ä»èŠ‚ç‚¹ä¸­é€å‡ºå·²ç»è¿è¡Œçš„podçš„æ±¡ç‚¹ï¼ˆeffect=NoExecuteï¼‰ã€‚</p><p>Taints and tolerations allow for complex use cases like having dedicated nodes for an exclusive set of Pods, or force eviction of Pods from problematic nodes by tainting those nodes.</p><p>æ±¡ç‚¹å’Œå®¹å¿å…è®¸å¤æ‚çš„ç”¨ä¾‹ï¼Œæ¯”å¦‚ä¸ºä¸€ç»„æ’ä»–çš„PODè®¾ç½®ä¸“ç”¨èŠ‚ç‚¹ï¼Œæˆ–è€…é€šè¿‡æ±¡ç‚¹è¿™äº›èŠ‚ç‚¹å¼ºåˆ¶ä»æœ‰é—®é¢˜çš„èŠ‚ç‚¹ä¸­é€å‡ºPODã€‚</p><p>You can influence the placement based on the applicationâ€™s high availability and performance needs, but try not to limit the scheduler too much and back yourself into a corner where no more Pods can be scheduled, and there are too many stranded resources. For example, if your containersâ€™ resource requirements are too coarsegrained, or nodes are too small, you may end up with stranded resources in nodes that are not utilized.</p><p>ä½ å¯ä»¥æ ¹æ®åº”ç”¨ç¨‹åºçš„é«˜å¯ç”¨æ€§å’Œæ€§èƒ½éœ€æ±‚æ¥å½±å“æ”¾ç½®ï¼Œä½†ä¸è¦å°è¯•è¿‡å¤šåœ°é™åˆ¶è°ƒåº¦å™¨ï¼Œè®©è‡ªå·±å›åˆ°ä¸€ä¸ªæ— æ³•å®‰æ’æ›´å¤šPODçš„è§’è½ï¼Œå› ä¸ºé‚£é‡Œæœ‰å¤ªå¤šææµ…çš„èµ„æºã€‚ä¾‹å¦‚ï¼Œå¦‚æœå®¹å™¨çš„èµ„æºéœ€æ±‚è¿‡äºç²—ç²’åº¦ï¼Œæˆ–è€…èŠ‚ç‚¹å¤ªå°ï¼Œé‚£ä¹ˆæœ€ç»ˆå¯èƒ½ä¼šå¯¼è‡´èŠ‚ç‚¹ä¸­çš„èµ„æºæ— æ³•ä½¿ç”¨ã€‚</p><p>In Figure 6-2, we can see node A has 4 GB of memory that cannot be utilized as there is no CPU left to place other containers. Creating containers with smaller resource requirements may help improve this situation. Another solution is to use the Kubernetes descheduler, which helps defragment nodes and improve their utilization.</p><p>åœ¨å›¾6-2ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°èŠ‚ç‚¹Aæœ‰4GBçš„å†…å­˜æ— æ³•ä½¿ç”¨ï¼Œå› ä¸ºæ²¡æœ‰å‰©ä½™çš„CPUæ¥æ”¾ç½®å…¶ä»–å®¹å™¨ã€‚åˆ›å»ºèµ„æºéœ€æ±‚è¾ƒå°çš„å®¹å™¨å¯èƒ½æœ‰åŠ©äºæ”¹å–„è¿™ç§æƒ…å†µã€‚å¦ä¸€ä¸ªè§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨Kubernetes deschedulerï¼Œè¿™æœ‰åŠ©äºå¯¹èŠ‚ç‚¹è¿›è¡Œç¢ç‰‡æ•´ç†å¹¶æé«˜å…¶åˆ©ç”¨ç‡</p><figure><img src="https://cdn.nlark.com/yuque/0/2021/png/2466332/1636032114208-49455920-5689-493b-ae72-656506e3844c.png#clientId=u0d4ab37c-7ab2-4&amp;from=paste&amp;height=563&amp;id=u2bfbb4db&amp;margin=[object Object]&amp;name=image.png&amp;originHeight=563&amp;originWidth=1322&amp;originalType=binary&amp;ratio=1&amp;size=99955&amp;status=done&amp;style=none&amp;taskId=u184e721b-159a-4ce3-a569-07193a5c5e8&amp;width=1322" alt="image.png" tabindex="0" loading="lazy"><figcaption>image.png</figcaption></figure><p>Figure 6-2. Processes scheduled to nodes and stranded resources</p><p>Once a Pod is assigned to a node, the job of the scheduler is done, and it does not change the placement of the Pod unless the Pod is deleted and recreated without a node assignment. As you have seen, with time, this can lead to resource fragmentation and poor utilization of cluster resources. Another potential issue is that the scheduler decisions are based on its cluster view at the point in time when a new Pod is scheduled. If a cluster is dynamic and the resource profile of the nodes changes or new nodes are added, the scheduler will not rectify its previous Pod placements. Apart from changing the node capacity, you may also alter the labels on the nodes that affect placement, but past placements are not rectified either.</p><p>ä¸€æ—¦å°†Podåˆ†é…ç»™èŠ‚ç‚¹ï¼Œè°ƒåº¦å™¨çš„å·¥ä½œå°±å®Œæˆäº†ï¼Œå¹¶ä¸”å®ƒä¸ä¼šæ›´æ”¹Podçš„ä½ç½®ï¼Œé™¤éåœ¨æœªåˆ†é…èŠ‚ç‚¹çš„æƒ…å†µä¸‹åˆ é™¤å¹¶é‡æ–°åˆ›å»ºPodã€‚æ­£å¦‚æ‚¨æ‰€çœ‹åˆ°çš„ï¼Œéšç€æ—¶é—´çš„æ¨ç§»ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´èµ„æºç¢ç‰‡åŒ–å’Œé›†ç¾¤èµ„æºåˆ©ç”¨ç‡ä½ä¸‹ã€‚å¦ä¸€ä¸ªæ½œåœ¨é—®é¢˜æ˜¯è°ƒåº¦å™¨çš„å†³ç­–æ˜¯åŸºäºå…¶åœ¨è°ƒåº¦æ–°Podæ—¶çš„é›†ç¾¤è§†å›¾ã€‚å¦‚æœé›†ç¾¤æ˜¯åŠ¨æ€çš„ï¼Œå¹¶ä¸”èŠ‚ç‚¹çš„èµ„æºé…ç½®æ–‡ä»¶å‘ç”Ÿäº†æ›´æ”¹æˆ–æ·»åŠ äº†æ–°èŠ‚ç‚¹ï¼Œåˆ™è°ƒåº¦ç¨‹åºå°†ä¸ä¼šçº æ­£å…¶ä»¥å‰çš„Podä½ç½®ã€‚é™¤äº†æ›´æ”¹èŠ‚ç‚¹å®¹é‡å¤–ï¼Œè¿˜å¯ä»¥æ›´æ”¹èŠ‚ç‚¹ä¸Šå½±å“æ”¾ç½®çš„æ ‡ç­¾ï¼Œä½†ä¹Ÿä¸ä¼šæ›´æ­£è¿‡å»çš„æ”¾ç½®ã€‚</p><p>All these are scenarios that can be addressed by the descheduler. The Kubernetes descheduler is an optional feature that typically is run as a Job whenever a cluster administrator decides it is a good time to tidy up and defragment a cluster by rescheduling the Pods. The descheduler comes with some predefined policies that can be enabled and tuned or disabled. The policies are passed as a file to the descheduler Pod, and currently, they are the following:</p><p>æ‰€æœ‰è¿™äº›éƒ½æ˜¯å¯ç”±å–æ¶ˆè®¡åˆ’è€…ï¼ˆdeschedulerï¼‰è§£å†³çš„åœºæ™¯ã€‚Kubernetes descheduleræ˜¯ä¸€ä¸ªå¯é€‰åŠŸèƒ½ï¼Œé€šå¸¸åœ¨ç¾¤é›†ç®¡ç†å‘˜å†³å®šé€šè¿‡é‡æ–°è°ƒåº¦PODæ¥æ•´ç†å’Œæ•´ç†ç¾¤é›†æ—¶ä½œä¸ºä½œä¸šè¿è¡Œã€‚descheduleré™„å¸¦äº†ä¸€äº›é¢„å®šä¹‰çš„ç­–ç•¥ï¼Œå¯ä»¥å¯ç”¨ã€è°ƒæ•´æˆ–ç¦ç”¨è¿™äº›ç­–ç•¥ã€‚è¿™äº›ç­–ç•¥ä½œä¸ºæ–‡ä»¶ä¼ é€’ç»™descheduler Podï¼Œç›®å‰å®ƒä»¬å¦‚ä¸‹æ‰€ç¤ºï¼š</p><ul><li><em>RemoveDuplicates</em> Â ç§»é™¤å‰¯æœ¬ç­–ç•¥ This strategy ensures that only a single Pod associated with a ReplicaSet or Deployment is running on a single node. If there are more Pods than one, these excess Pods are evicted. This strategy is useful in scenarios where a node has become unhealthy, and the managing controllers started new Pods on other healthy nodes. When the unhealthy node is recovered and joins the cluster, the number of running Pods is more than desired, and the descheduler can help bring the numbers back to the desired replicas count. Removing duplicates on nodes can also help with the spread of Pods evenly on more nodes when scheduling policies and cluster topology have changed after the initial placement. æ­¤ç­–ç•¥ç¡®ä¿åœ¨å•ä¸ªèŠ‚ç‚¹ä¸Šä»…è¿è¡Œä¸ReplicaSetæˆ–Deploymentå…³è”çš„å•ä¸ªPodã€‚å¦‚æœæœ‰å¤šä¸ªPODï¼Œè¿™äº›å¤šä½™çš„PODå°†è¢«é€å‡ºã€‚åœ¨èŠ‚ç‚¹å˜å¾—ä¸å¥åº·ï¼Œå¹¶ä¸”ç®¡ç†æ§åˆ¶å™¨åœ¨å…¶ä»–å¥åº·èŠ‚ç‚¹ä¸Šå¯åŠ¨æ–°PODçš„æƒ…å†µä¸‹ï¼Œæ­¤ç­–ç•¥éå¸¸æœ‰ç”¨ã€‚å½“ä¸å¥åº·èŠ‚ç‚¹æ¢å¤å¹¶åŠ å…¥é›†ç¾¤æ—¶ï¼Œæ­£åœ¨è¿è¡Œçš„PODçš„æ•°é‡è¶…è¿‡é¢„æœŸï¼Œè€Œdeschedulerå¯ä»¥å¸®åŠ©å°†è¿™äº›æ•°é‡æ¢å¤åˆ°é¢„æœŸçš„å‰¯æœ¬æ•°é‡ã€‚å½“è°ƒåº¦ç­–ç•¥å’Œé›†ç¾¤æ‹“æ‰‘åœ¨åˆå§‹æ”¾ç½®åå‘ç”Ÿæ›´æ”¹æ—¶ï¼Œåˆ é™¤èŠ‚ç‚¹ä¸Šçš„é‡å¤é¡¹ä¹Ÿæœ‰åŠ©äºå°†PODå‡åŒ€åœ°åˆ†å¸ƒåœ¨æ›´å¤šèŠ‚ç‚¹ä¸Šã€‚</li><li><em>LowNodeUtilization</em> ä½èŠ‚ç‚¹åˆ©ç”¨ç‡ç­–ç•¥ This strategy finds nodes that are underutilized and evicts Pods from other overutilized nodes, hoping these Pods will be placed on the underutilized nodes, leading to better spread and use of resources. The underutilized nodes are identified as nodes with CPU, memory, or Pod count below the configured thresholds values. Similarly, overutilized nodes are those with values greater than the configured targetThresholds values. Any node between these values is appropriately utilized and not affected by this strategy. æ­¤ç­–ç•¥ä¼šå‘ç°æœªå……åˆ†åˆ©ç”¨çš„èŠ‚ç‚¹ï¼Œå¹¶ä»å…¶ä»–è¿‡åº¦åˆ©ç”¨çš„èŠ‚ç‚¹ä¸­é€å‡ºPODï¼Œå¸Œæœ›è¿™äº›PODå°†æ”¾ç½®åœ¨æœªå……åˆ†åˆ©ç”¨çš„èŠ‚ç‚¹ä¸Šï¼Œä»è€Œæ›´å¥½åœ°ä¼ æ’­å’Œä½¿ç”¨èµ„æºã€‚æœªå……åˆ†åˆ©ç”¨çš„èŠ‚ç‚¹è¢«æ ‡è¯†ä¸ºCPUã€å†…å­˜æˆ–Podè®¡æ•°ä½äºé…ç½®é˜ˆå€¼çš„èŠ‚ç‚¹ã€‚ç±»ä¼¼åœ°ï¼Œè¿‡åº¦åˆ©ç”¨çš„èŠ‚ç‚¹æ˜¯é‚£äº›å€¼å¤§äºé…ç½®çš„targetThresholdså€¼çš„èŠ‚ç‚¹ã€‚è¿™äº›å€¼ä¹‹é—´çš„ä»»ä½•èŠ‚ç‚¹éƒ½è¢«é€‚å½“åœ°åˆ©ç”¨ï¼Œå¹¶ä¸”ä¸å—æ­¤ç­–ç•¥çš„å½±å“ã€‚</li><li><em>RemovePodsViolatingInterPodAntiAffinity</em> ç§»é™¤è¿åPODåäº²å’ŒåŠ›ï¼ˆåå…³è”ï¼‰çš„ç­–ç•¥ This strategy evicts Pods violating interpod antiaffinity rules, which could happen when the antiaffinity rules are added after the Pods have been placed on the nodes. æ­¤ç­–ç•¥ä¼šé€å‡ºè¿åå†…éƒ¨PODåäº²å’Œè§„åˆ™çš„podï¼Œè¿™å¯èƒ½å‘ç”Ÿåœ¨å°†podæ”¾ç½®åœ¨èŠ‚ç‚¹ä¸Šåæ·»åŠ åäº²å’Œè§„åˆ™æ—¶ã€‚</li><li><em>RemovePodsViolatingNodeAffinity</em> ç§»é™¤è¿åPODäº²å’ŒåŠ›ï¼ˆå…³è”ï¼‰çš„ç­–ç•¥ This strategy is for evicting Pods violating node affinity rules. æ­¤ç­–ç•¥ç”¨äºé€å‡ºè¿åèŠ‚ç‚¹å…³è”è§„åˆ™çš„PODã€‚</li></ul><p>Regardless of the policy used, the descheduler avoids evicting the following:</p><p>æ— è®ºä½¿ç”¨ä½•ç§ç­–ç•¥ï¼Œå–æ¶ˆè®¡åˆ’ç¨‹åº(descheduler )éƒ½ä¼šé¿å…æ”¶å›ä»¥ä¸‹å†…å®¹ï¼š</p><ul><li>Critical Pods that are marked with <code>scheduler.alpha.kubernetes.io/criticalpod</code> annotation.</li><li>ç”¨<code>scheduler.alpha.kubernetes.io/criticalpod</code>æ³¨é‡Šæ ‡è®°çš„å…³é”®podã€‚</li><li>Pods not managed by a ReplicaSet, Deployment, or Job.</li><li>ä¸æ˜¯ç”±å¤åˆ¶é›†ã€éƒ¨ç½²æˆ–ä½œä¸šç®¡ç†çš„PODsã€‚</li><li>Pods managed by a DaemonSet.</li><li>ç”±å®ˆæŠ¤è¿›ç¨‹é›†ç®¡ç†çš„PODsã€‚</li><li>Pods that have local storage.</li><li>å…·æœ‰æœ¬åœ°å­˜å‚¨çš„Podsã€‚</li><li>Pods with PodDisruptionBudget where eviction would violate its rules.</li><li>å¸¦æœ‰PodDisruptionBudgetçš„Podï¼Œé©±é€å°†è¿åå…¶è§„åˆ™ã€‚</li><li>Deschedule Pod itself (achieved by marking itself as a critical Pod).</li><li>Deschedule Podæœ¬èº«ï¼ˆé€šè¿‡å°†è‡ªèº«æ ‡è®°ä¸ºå…³é”®Podå®ç°ï¼‰ã€‚</li></ul><p>Of course, all evictions respect Podsâ€™ QoS levels by choosing Best-Efforts Pods first, then Burstable Pods, and finally Guaranteed Pods as candidates for eviction. See Chapter 2, Predictable Demands for a detailed explanation of these QoS levels.</p><p>å½“ç„¶ï¼Œæ‰€æœ‰è¿å‡ºéƒ½å°Šé‡PODçš„QoSçº§åˆ«ï¼Œé¦–å…ˆé€‰æ‹©Best-Effortsçš„PODï¼Œç„¶åé€‰æ‹©Burstable PODï¼Œæœ€åé€‰æ‹©Guaranteed çš„PODä½œä¸ºè¿å‡ºçš„å€™é€‰PODã€‚æœ‰å…³è¿™äº›QoSçº§åˆ«çš„è¯¦ç»†è¯´æ˜ï¼Œè¯·å‚è§ç¬¬2ç« ç¬¬1èŠ‚ä¸­çš„â€œå¯é¢„æµ‹éœ€æ±‚â€ã€‚</p><h3 id="_2-5-3-discussion-è®¨è®º" tabindex="-1"><a class="header-anchor" href="#_2-5-3-discussion-è®¨è®º" aria-hidden="true">#</a> 2.5.3 Discussion Â è®¨è®º</h3><p>Placement is an area where you want to have as minimal intervention as possible. If you follow the guidelines from Chapter 2, Predictable Demands and declare all the resource needs of a container, the scheduler will do its job and place the Pod on the most suitable node possible. However, when that is not enough, there are multiple ways to steer the scheduler toward the desired deployment topology. To sum up, from simpler to more complex, the following approaches control Pod scheduling (keep in mind, as of this writing, this list changes with every other release of Kubernetes):</p><p>æ”¾ç½®Podæ˜¯ä¸€ä¸ªå¸Œæœ›å°½å¯èƒ½å°‘å¹²é¢„çš„é¢†åŸŸã€‚å¦‚æœéµå¾ªâ€œå¯é¢„æµ‹çš„éœ€æ±‚â€ç« èŠ‚ä¸­çš„æŒ‡å¯¼åŸåˆ™å¹¶å£°æ˜å®¹å™¨çš„æ‰€æœ‰èµ„æºéœ€æ±‚ï¼Œè°ƒåº¦ç¨‹åºå°†å®Œæˆå…¶å·¥ä½œå¹¶å°†Podæ”¾ç½®åœ¨æœ€åˆé€‚çš„èŠ‚ç‚¹ä¸Šã€‚ä½†æ˜¯ï¼Œå½“è¿™è¿˜ä¸å¤Ÿæ—¶ï¼Œæœ‰å¤šç§æ–¹æ³•å¯ä»¥å°†è°ƒåº¦å™¨å¯¼å‘æ‰€éœ€çš„éƒ¨ç½²æ‹“æ‰‘ã€‚æ€»ä¹‹ï¼Œä»ç®€å•åˆ°å¤æ‚ï¼Œä»¥ä¸‹æ–¹æ³•æ§åˆ¶Podè°ƒåº¦ï¼ˆè¯·è®°ä½ï¼Œåœ¨æ’°å†™æœ¬æ–‡æ—¶ï¼Œæ­¤åˆ—è¡¨ä¼šéšç€Kubernetesçš„å…¶ä»–ç‰ˆæœ¬è€Œå˜åŒ–ï¼‰ï¼š</p><ul><li><em>nodeName</em> èŠ‚ç‚¹åç§° The simplest form of hardwiring a Pod to a node. This field should ideally be populated by the scheduler, which is driven by policies rather than manual node assignment. Assigning a Pod to a node limits greatly where a Pod can be scheduled. This throws us back in to the pre-Kubernetes era when we explicitly specified the nodes to run our applications. å°†Podç¡¬è¿æ¥åˆ°èŠ‚ç‚¹çš„æœ€ç®€å•å½¢å¼ã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œæ­¤å­—æ®µåº”ç”±è°ƒåº¦ç¨‹åºå¡«å……ï¼Œè°ƒåº¦ç¨‹åºç”±ç­–ç•¥é©±åŠ¨ï¼Œè€Œä¸æ˜¯æ‰‹åŠ¨åˆ†é…èŠ‚ç‚¹ã€‚å°†Podåˆ†é…ç»™èŠ‚ç‚¹æå¤§åœ°é™åˆ¶äº†å¯ä»¥è°ƒåº¦Podçš„ä½ç½®ã€‚è¿™è®©æˆ‘ä»¬å›åˆ°äº†Kubernetesä¹‹å‰çš„æ—¶ä»£ï¼Œå½“æ—¶æˆ‘ä»¬æ˜ç¡®æŒ‡å®šäº†è¿è¡Œåº”ç”¨ç¨‹åºçš„èŠ‚ç‚¹ã€‚</li><li><em>nodeSelector</em> èŠ‚ç‚¹é€‰æ‹©å™¨ Specification of a map of key-value pairs. For the Pod to be eligible to run on a node, the Pod must have the indicated key-value pairs as the label on the node. Having put some meaningful labels on the Pod and the node (which you should do anyway), a node selector is one of the simplest acceptable mechanisms for controlling the scheduler choices. é”®å€¼å¯¹æ˜ å°„çš„è§„èŒƒã€‚ä¸ºäº†ä½¿Podæœ‰èµ„æ ¼åœ¨èŠ‚ç‚¹ä¸Šè¿è¡Œï¼ŒPodå¿…é¡»å…·æœ‰æŒ‡ç¤ºçš„é”®å€¼å¯¹ä½œä¸ºèŠ‚ç‚¹ä¸Šçš„æ ‡ç­¾ã€‚åœ¨Podå’ŒèŠ‚ç‚¹ä¸Šæ”¾ç½®äº†ä¸€äº›æœ‰æ„ä¹‰çš„æ ‡ç­¾ï¼ˆæ— è®ºå¦‚ä½•éƒ½åº”è¯¥è¿™æ ·åšï¼‰ï¼ŒèŠ‚ç‚¹é€‰æ‹©å™¨æ˜¯æ§åˆ¶è°ƒåº¦å™¨é€‰æ‹©çš„æœ€ç®€å•çš„å¯æ¥å—æœºåˆ¶ä¹‹ä¸€ã€‚</li><li><em>Default scheduling alteration</em> é»˜è®¤è°ƒåº¦æ›¿ä»£ The default scheduler is responsible for the placement of new Pods onto nodes within the cluster, and it does it reasonably. However, it is possible to alter the filtering and priority policies list, order, and weight of this scheduler if necessary. é»˜è®¤çš„è°ƒåº¦å™¨è´Ÿè´£å°†æ–°çš„podæ”¾ç½®åˆ°é›†ç¾¤å†…çš„èŠ‚ç‚¹ä¸Šï¼Œå¹¶ä¸”å®ƒåšå¾—å¾ˆåˆç†ã€‚ä½†æ˜¯ï¼Œå¦‚æœéœ€è¦ï¼Œå¯ä»¥æ›´æ”¹æ­¤è®¡åˆ’ç¨‹åºçš„ç­›é€‰å’Œä¼˜å…ˆçº§ç­–ç•¥åˆ—è¡¨ã€é¡ºåºå’Œæƒé‡ã€‚</li><li><em>Pod affinity and antiaffinity</em> Â Podçš„äº²å’Œæ€§å’Œåäº²å’Œæ€§ These rules allow a Pod to express dependencies on other Pods. For example, for an applicationâ€™s latency requirements, high availability, security constraints, and so forth. è¿™äº›è§„åˆ™å…è®¸Podè¡¨è¾¾å¯¹å…¶ä»–Podçš„ä¾èµ–å…³ç³»ã€‚ä¾‹å¦‚ï¼Œå¯¹äºåº”ç”¨ç¨‹åºçš„å»¶è¿Ÿè¦æ±‚ã€é«˜å¯ç”¨æ€§ã€å®‰å…¨çº¦æŸç­‰ã€‚</li><li><em>Node affinity</em> Â èŠ‚ç‚¹çš„äº²å’Œæ€§ This rule allows a Pod to express dependency toward nodes. For example, considering nodesâ€™ hardware, location, and so forth. æ­¤è§„åˆ™å…è®¸Podè¡¨ç¤ºå¯¹èŠ‚ç‚¹çš„ä¾èµ–å…³ç³»ã€‚ä¾‹å¦‚ï¼Œè€ƒè™‘èŠ‚ç‚¹çš„ç¡¬ä»¶ã€ä½ç½®ç­‰ã€‚</li><li><em>Taints and tolerations</em> Taints and tolerations allow the node to control which Pods should or should not be scheduled on them. For example, to dedicate a node for a group of Pods, or even evict Pods at runtime. Another advantage of Taints and Tolerations is that if you expand the Kubernetes cluster by adding new nodes with new labels, you donâ€™t need to add the new labels on all the Pods, but only on the Pods that should be placed on the new nodes. æ±¡ç‚¹å’Œå®¹å¿å…è®¸èŠ‚ç‚¹æ§åˆ¶åº”è¯¥æˆ–ä¸åº”è¯¥åœ¨å…¶ä¸Šè°ƒåº¦å“ªäº›podã€‚ä¾‹å¦‚ï¼Œå°†ä¸€ä¸ªèŠ‚ç‚¹ä¸“ç”¨äºä¸€ç»„podï¼Œç”šè‡³åœ¨è¿è¡Œæ—¶æ”¶å›podã€‚æ±¡ç‚¹å’Œå®¹å¿çš„å¦ä¸€ä¸ªä¼˜ç‚¹æ˜¯ï¼Œå¦‚æœé€šè¿‡æ·»åŠ å¸¦æœ‰æ–°æ ‡ç­¾çš„æ–°èŠ‚ç‚¹æ¥æ‰©å±•Kubernetesé›†ç¾¤ï¼Œåˆ™ä¸éœ€è¦åœ¨æ‰€æœ‰PODä¸Šæ·»åŠ æ–°æ ‡ç­¾ï¼Œè€Œåªéœ€è¦åœ¨åº”æ”¾ç½®åœ¨æ–°èŠ‚ç‚¹ä¸Šçš„PODä¸Šæ·»åŠ æ–°æ ‡ç­¾ã€‚</li><li><em>Custom scheduler</em> If none of the preceding approaches is good enough, or maybe you have complex scheduling requirements, you can also write your custom scheduler. A custom scheduler can run instead of, or alongside, the standard Kubernetes scheduler. A hybrid approach is to have a â€œscheduler extenderâ€ process that the standard Kubernetes scheduler calls out to as a final pass when making scheduling decisions. This way you donâ€™t have to implement a full scheduler, but only provide HTTP APIs to filter and prioritize nodes. The advantage of having your scheduler is that you can consider factors outside of the Kubernetes cluster like hardware cost, network latency, and better utilization while assigning Pods to nodes. You can also use multiple custom schedulers alongside the default scheduler and configure which scheduler to use for each Pod. Each scheduler could have a different set of policies dedicated to a subset of the Pods. å¦‚æœå‰é¢çš„æ–¹æ³•éƒ½ä¸å¤Ÿå¥½ï¼Œæˆ–è€…ä½ æœ‰å¤æ‚çš„è°ƒåº¦éœ€æ±‚ï¼Œé‚£ä¹ˆä½ ä¹Ÿå¯ä»¥ç¼–å†™è‡ªå®šä¹‰è°ƒåº¦ç¨‹åºã€‚è‡ªå®šä¹‰è°ƒåº¦å™¨å¯ä»¥ä»£æ›¿æ ‡å‡†Kubernetesè°ƒåº¦å™¨è¿è¡Œï¼Œä¹Ÿå¯ä»¥ä¸æ ‡å‡†Kubernetesè°ƒåº¦å™¨å¹¶è¡Œè¿è¡Œã€‚ä¸€ç§æ··åˆæ–¹æ³•æ˜¯æœ‰ä¸€ä¸ªâ€œè°ƒåº¦å™¨æ‰©å±•å™¨â€è¿›ç¨‹ï¼Œæ ‡å‡†Kubernetesè°ƒåº¦å™¨åœ¨åšå‡ºè°ƒåº¦å†³ç­–æ—¶è°ƒç”¨è¯¥è¿›ç¨‹ä½œä¸ºæœ€ç»ˆè¿‡ç¨‹ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œä½ ä¸å¿…å®ç°å®Œæ•´çš„è°ƒåº¦ç¨‹åºï¼Œåªéœ€æä¾›HTTP APIæ¥è¿‡æ»¤èŠ‚ç‚¹å¹¶ç¡®å®šå…¶ä¼˜å…ˆçº§ã€‚æ‹¥æœ‰è°ƒåº¦å™¨çš„ä¼˜ç‚¹åœ¨äºï¼Œå¯ä»¥è€ƒè™‘åœ¨åº“ä¼¯ç½‘ç»œé›†ç¾¤ä¹‹å¤–çš„å› ç´ ï¼Œå¦‚ç¡¬ä»¶æˆæœ¬ã€ç½‘ç»œå»¶è¿Ÿå’Œæ›´å¥½çš„åˆ©ç”¨ï¼ŒåŒæ—¶å°†èŠ‚ç‚¹åˆ†é…ç»™èŠ‚ç‚¹ã€‚ä½ è¿˜å¯ä»¥åœ¨é»˜è®¤è°ƒåº¦ç¨‹åºæ—è¾¹ä½¿ç”¨å¤šä¸ªè‡ªå®šä¹‰è°ƒåº¦ç¨‹åºï¼Œå¹¶é…ç½®æ¯ä¸ªPodè¦ä½¿ç”¨çš„è°ƒåº¦ç¨‹åºã€‚æ¯ä¸ªè°ƒåº¦å™¨å¯ä»¥æœ‰ä¸€ç»„ä¸åŒçš„ç­–ç•¥ï¼Œä¸“ç”¨äºPODçš„ä¸€ä¸ªå­é›†ã€‚</li></ul><p>As you can see, there are lots of ways to control the Pod placement and choosing the right approach or combining multiple approaches can be challenging. The takeaway from this chapter is this: size and declare container resource profiles, label Pods and nodes accordingly, and finally, do only a minimal intervention to the Kubernetes scheduler.</p><p>æ­£å¦‚ä½ æ‰€è§ï¼Œæœ‰å¾ˆå¤šæ–¹æ³•å¯ä»¥æ§åˆ¶Podçš„æ”¾ç½®ï¼Œé€‰æ‹©æ­£ç¡®çš„æ–¹æ³•æˆ–ç»„åˆå¤šç§æ–¹æ³•å¯èƒ½æ˜¯ä¸€é¡¹æŒ‘æˆ˜ã€‚æœ¬ç« çš„è¦ç‚¹æ˜¯ï¼šè°ƒæ•´å’Œå£°æ˜å®¹å™¨èµ„æºé…ç½®æ–‡ä»¶ï¼Œç›¸åº”åœ°æ ‡è®°podå’ŒèŠ‚ç‚¹ï¼Œæœ€åï¼Œåªå¯¹Kubernetesè°ƒåº¦ç¨‹åºè¿›è¡Œæœ€å°çš„å¹²é¢„ã€‚</p></div><!----><footer class="page-meta"><div class="meta-item edit-link"><a href="https://github.com/Aiyin5/Aiyin5.github.io/edit/main/docs/zh/posts/æ–‡ç« ç¿»è¯‘/K8sæ¨¡å¼/K8såŸºç¡€æ¨¡å¼/è‡ªåŠ¨åŒ–å¸ƒå±€ï¼ˆPodçš„æ”¾ç½®ï¼‰.md" rel="noopener noreferrer" target="_blank" aria-label="åœ¨ GitHub ä¸Šç¼–è¾‘æ­¤é¡µ" class="nav-link label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->åœ¨ GitHub ä¸Šç¼–è¾‘æ­¤é¡µ<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div><div class="meta-item update-time"><span class="label">ä¸Šæ¬¡ç¼–è¾‘äº: </span><!----></div><div class="meta-item contributors"><span class="label">è´¡çŒ®è€…: </span><!--[--><!--[--><span class="contributor" title="email: 372020407@qq.com">aiyin</span><!--]--><!--]--></div></footer><nav class="page-nav"><a href="/zh/posts/%E6%96%87%E7%AB%A0%E7%BF%BB%E8%AF%91/K8s%E6%A8%A1%E5%BC%8F/K8s%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%BC%8F/%E6%89%98%E7%AE%A1%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.html" class="nav-link prev" aria-label="åŸºç¡€æ¨¡å¼ æ‰˜ç®¡ç”Ÿå‘½å‘¨æœŸ"><div class="hint"><span class="arrow left"></span>ä¸Šä¸€é¡µ</div><div class="link"><span class="icon iconfont icon-page"></span>åŸºç¡€æ¨¡å¼ æ‰˜ç®¡ç”Ÿå‘½å‘¨æœŸ</div></a><!----></nav><!----><!----><!--]--></main><!--]--><footer class="footer-wrapper"><div class="footer"><a href="/about/About">å…³äºç½‘ç«™</a></div><div class="copyright">Copyright Â© 2023 è‰¾å› </div></footer><!--]--></div><!--]--><!----><!--]--></div>
    <script type="module" src="/assets/app-e590ba2f.js" defer></script>
  </body>
</html>
