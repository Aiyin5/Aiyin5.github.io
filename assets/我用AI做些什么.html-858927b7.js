import{_ as i,V as s,W as r,X as e,Y as t,Z as a,$ as o,D as l}from"./framework-e28fa486.js";const h="/assets/photo/Askio的产品介绍.png",d="/assets/photo/sd原理.png",p="/assets/mp4/sadTalk1.mp4",c="/assets/mp4/sadTalk2.mp4",_="/assets/photo/语音小程序.png",u="/assets/mp4/Digital_Human.mp4",f={},b=o('<h1 id="我用ai做了些什么" tabindex="-1"><a class="header-anchor" href="#我用ai做了些什么" aria-hidden="true">#</a> 我用AI做了些什么</h1><p>在2023年的年初，我、五一和Ego一起参加了SeeDao的工作坊，和SeeDao一起实现了一个基于SeeDao notion数据的新人引导机器人，并拿到了二等奖。 至此我们走上了AI应用的开发和学习的道路。下面是我和我的团队在这半年里面一起完成的关于AI应用相关的内容。</p><p>关于大模型的一些基本概念可以看这个链接： <a href="AI%E5%BA%94%E7%94%A8%E7%9A%84%E5%88%86%E4%BA%AB">AI应用技术的分享</a></p><p>在这半年中我尝试了各类大模型，包括文字、图像和语音。以下将从这几个方面介绍我对这些大模型的认知以及我和我的团队基于这些大模型实现的应用。</p><p>这是一篇关于大模型应用和基础介绍的文章，因为我个人的水平和能力有限，会有很多内容出错或者表达偏差，欢迎指正。</p><h2 id="文字推理及生成" tabindex="-1"><a class="header-anchor" href="#文字推理及生成" aria-hidden="true">#</a> 文字推理及生成</h2>',6),g={href:"https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web",target:"_blank",rel:"noopener noreferrer"},m=e("strong",null,"ChatGPT Is a Blurry JPEG of the Web",-1),k=e("p",null,"可以将ChatGPT等大语言模型视为网上所有文本的压缩数据。就像一张模糊的JPEG，是对图片的有损压缩。 GPT对文本内容的补全和JPEG数据恢复成图像，都是在已有数据基础上，根据概率，对缺失数据进行填充。",-1),w=e("h4",{id:"当前比较主流的文字推理大模型",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#当前比较主流的文字推理大模型","aria-hidden":"true"},"#"),t(" 当前比较主流的文字推理大模型")],-1),S=e("thead",null,[e("tr",null,[e("th",null,"名称"),e("th",null,"网站"),e("th",null,"上下文大小"),e("th",null,"特点")])],-1),A=e("td",null,"GPT(3.5&4)",-1),T={href:"https://beta.openai.com/",target:"_blank",rel:"noopener noreferrer"},y=e("td",null,"4K-32K",-1),x=e("td",null,"非开源，GPT-4的能力在数学、代码方面暂时是最强的",-1),I=e("td",null,"LLAMA1&2)",-1),v={href:"https://github.com/facebookresearch/llama",target:"_blank",rel:"noopener noreferrer"},V=e("td",null,"/",-1),D=e("td",null,"meta开源的，最近最火的，易于微调",-1),P=e("td",null,"Claude(1&2)",-1),C={href:"https://claude.ai/",target:"_blank",rel:"noopener noreferrer"},G=e("td",null,"100K(约65000单词)",-1),B=e("td",null,"可以接收PDF/txt附件，实现超长文本的翻译，总结，以及代码翻译",-1),E=e("td",null,"通义千问",-1),z={href:"https://tongyi.aliyun.com/",target:"_blank",rel:"noopener noreferrer"},J=e("td",null,"4k",-1),L=e("td",null,"可以说是国内性能比较好的大模型，在阿里灵积模型开放api，v1版本开源。",-1),N=e("td",null,"ChatGlm-6b",-1),M={href:"https://maas.aminer.cn/",target:"_blank",rel:"noopener noreferrer"},U=e("td",null,"4k-16k",-1),j=e("td",null,"国内最早开源的一批家用显卡可以部署和微调的模型",-1),K={href:"https://zhuanlan.zhihu.com/p/619083290",target:"_blank",rel:"noopener noreferrer"},X=e("strong",null,"大语言模型的综述",-1),Z=e("h3",{id:"基于知识库的企业问答机器人askio",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#基于知识库的企业问答机器人askio","aria-hidden":"true"},"#"),t(" 基于知识库的企业问答机器人ASKIO")],-1),F=e("p",null,"Askio是我这半年里面最主要的项目，其本质是一个基于本地知识库的问答机器人。 整个项目的核心有两个，一个是如何将非结构化数据转换为结构化数据， 第二个是如何实现高效和高质量的检索并与LLM交互。",-1),O={href:"https://www.bilibili.com/video/BV1Zz4y1g77J",target:"_blank",rel:"noopener noreferrer"},H=e("p",null,[e("video",{src:"https://www.bilibili.com/video/BV1Zz4y1g77J",width:"720",height:"360",controls:""})],-1),W={href:"https://www.askio.xyz",target:"_blank",rel:"noopener noreferrer"},q=o('<p>Askio的产品介绍图如下:</p><figure><img src="'+h+'" alt="Askio的产品介绍.png" tabindex="0" loading="lazy"><figcaption>Askio的产品介绍.png</figcaption></figure><p>关于以下的技术实现和细节，如果你有任何的想法和思路，或者想探索，都可以跟我来聊一聊：</p><ul><li>如何将非结构数据转换为结构化数据，采用向量（embeding）、知识图谱等方法，如何高效和准确的实现。</li><li>基于向量数据库的混合检索、稀疏向量匹配、源数据召回、上下文压缩等问题。</li></ul><h2 id="图像生成及推理" tabindex="-1"><a class="header-anchor" href="#图像生成及推理" aria-hidden="true">#</a> 图像生成及推理</h2><p>图像生成领域的大模型和软件在业界中还是比较少的，出名的有MJ（midjourney）和SD(stable diffusion)</p><p>Midjourney在参考CLIP及Diffusion开源模型的基础上，构建自己的垂类SaaS产品。</p><p>MJ更像是众多sd模型的混合版本，根据提示词实现了模型风格，模型类型的自动选择。</p><p>在图像生成的领域，我没有进行模型的微调和模型底层开发相关的经验，仅有使用SD的一些应用经验。</p><p>简单的描述一下图像生成大模型的实现原理，以下是基于SD1.0和SD1.5版本的，近期SDXL的出现，其实现原理更复杂和精细。</p><figure><img src="'+d+'" alt="sd原理.png" tabindex="0" loading="lazy"><figcaption>sd原理.png</figcaption></figure><p>其本质跟语言类的推理大模型是一样，是一个端到端的推理模型，只是输入的编码器和输出的解码器不一样。</p>',12),Y={href:"https://www.youtube.com/watch?v=1CIpzeNxIhU",target:"_blank",rel:"noopener noreferrer"},$={href:"https://jalammar.github.io/illustrated-stable-diffusion/",target:"_blank",rel:"noopener noreferrer"},Q={href:"https://medium.com/@steinsfu/stable-diffusion-clearly-explained-ed008044e07e",target:"_blank",rel:"noopener noreferrer"},R=e("h3",{id:"一些有趣的图像-视频模型推荐",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#一些有趣的图像-视频模型推荐","aria-hidden":"true"},"#"),t(" 一些有趣的图像/视频模型推荐")],-1),ee=e("thead",null,[e("tr",null,[e("th",null,"模型名称"),e("th",null,"github地址"),e("th",null,"功能"),e("th",null,"其他")])],-1),te=e("td",null,"stable diffusion",-1),ne={href:"https://github.com/CompVis/stable-diffusion",target:"_blank",rel:"noopener noreferrer"},ae=e("td",null,"根据文字/图片生成图片",-1),oe=e("td",null,"webUI及部署方法可以参考秋葉aaaki的视频",-1),ie=e("td",null,"SadTalk",-1),se={href:"https://github.com/OpenTalker/SadTalker",target:"_blank",rel:"noopener noreferrer"},re=e("td",null,"基于照片和语音生成人物表情和嘴型视频",-1),le=e("td",null,"sd webui上有集成插件",-1),he=e("td",null,"segment anything",-1),de={href:"https://github.com/facebookresearch/segment-anything",target:"_blank",rel:"noopener noreferrer"},pe=e("td",null,"meta开源的抠图大模型，可以根据文本抠图",-1),ce=e("td",null,"sd webui上有集成插件",-1),_e=e("td",null,"DrapGen",-1),ue={href:"https://github.com/XingangPan/DragGAN",target:"_blank",rel:"noopener noreferrer"},fe=e("td",null,"可以拖动图片中任意物体的大模型",-1),be=e("td",null,null,-1),ge=e("h3",{id:"基于sd的ai视频制作",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#基于sd的ai视频制作","aria-hidden":"true"},"#"),t(" 基于SD的AI视频制作")],-1),me=e("p",null,"Maro(彭生)和我在最近的几个月里面，一直在研究AI视频制作，采用了很多方法和尝试。 在AI视频生成和制作中，我认为最难和最复杂的和正常拍视频是一样的，是想法和脚本构思，其次是AI如何配合这些想法和剧情脚本，包括后期如何让AI视频不闪之类的。",-1),ke=e("h3",{id:"ai视频的展示",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#ai视频的展示","aria-hidden":"true"},"#"),t(" AI视频的展示")],-1),we={href:"https://www.bilibili.com/video/BV1d94y1i7PA/",target:"_blank",rel:"noopener noreferrer"},Se=o('<p><video src="https://www.bilibili.com/video/BV1d94y1i7PA/" width="720" height="360" controls></video></p><p>这是一个连续剧，下一集即将完成，同时剧情和技术也有了很大的提升。</p><h3 id="基于sadtalk的图片生成数字人" tabindex="-1"><a class="header-anchor" href="#基于sadtalk的图片生成数字人" aria-hidden="true">#</a> 基于SadTalk的图片生成数字人</h3><p>下面这个demo是采用Askio的英文介绍通过SadTalk生成的AI视频</p><p><video src="'+p+'" width="360" height="360" controls></video></p><p>这个demo是采用中文东北话生成的AI视频</p><p><video src="'+c+'" width="360" height="360" controls></video></p><p>原始图像是通过SD生成</p><h2 id="语音生成及推理" tabindex="-1"><a class="header-anchor" href="#语音生成及推理" aria-hidden="true">#</a> 语音生成及推理</h2><h3 id="关于市面上的语音合成技术" tabindex="-1"><a class="header-anchor" href="#关于市面上的语音合成技术" aria-hidden="true">#</a> 关于市面上的语音合成技术</h3><p>语音合成的两种方式：TTS和VCS</p><p>TTS和VCS是两种不同的技术，分别用于语音合成和语音转换。</p><p>TTS（Text-to-Speech）是一种语音合成技术，它将文本转换为人类可以听懂的语音。使用TTS技术，计算机可以自动将文本转换为语音，而无需人类语音演讲者的参与。TTS技术可以用于语音助手、自动语音应答系统、有声读物等领域。</p><p>VCS（Voice Conversion System）是一种语音转换技术，它可以将一个人的语音转换成另一个人的语音，而不改变语音的内容和意义。VCS技术可以用于语音模仿、语音变声、语音匹配等领域。</p><p>虽然TTS和VCS都涉及到语音技术，但它们的应用场景和技术原理都有所不同。TTS主要用于将文本转换为语音，而VCS则用于语音转换和模仿。</p><h2 id="语音相关的大模型" tabindex="-1"><a class="header-anchor" href="#语音相关的大模型" aria-hidden="true">#</a> 语音相关的大模型</h2><h3 id="基于vist的语音克隆" tabindex="-1"><a class="header-anchor" href="#基于vist的语音克隆" aria-hidden="true">#</a> 基于VIST的语音克隆</h3><p>当前我只研究了一下TTS相关的合成技术，没有研究VCS相关的技术，以下都是属于TTS的模型训练方式</p><p>当前主流的模型有基于Vits模型衍生出来的一系列模型和类似FastSpeech的Parallel模型，都可以在极低的训练数据下产生不错的效果</p><p>这两种模型的实现方式是非常类似的，训练过程也基本一致。</p><p>训练一个语音模型需要经历以下的步骤：</p><p>准备预训练模型，也可以称为底模</p><p>准备训练的数据集，一般10-20短10秒以内的语音文件</p><p>对数据集进行降噪，并进行语音识别</p><p>最终标准的训练数据为10-20组短语音文件和对应的中文识别文字</p><p>进行训练（通常采用GPU进行），大约100个训练周期，约为10-20分钟，可以生成一个微调模型，也就是最终的语音模型。</p><p>该模型的效果取决于底模（预训练模型）+训练数据和训练时长决定，按照上面的训练方式可以实现大约70%的相似效果。</p><h2 id="混合应用" tabindex="-1"><a class="header-anchor" href="#混合应用" aria-hidden="true">#</a> 混合应用</h2><p>这边定义的混合应用，一般是指使用多个模型或者多个能力串行/并行实现的一个软件或者功能。</p><p>例如数字人/AI孪生就是比较复杂的应用，一般包含了语音识别、语音克隆、语音合成、文本驱动3D模型、情感分析等模块，每一个模块或多或少都应用到了大模型的能力。</p><h3 id="ai语音交互抖音小程序" tabindex="-1"><a class="header-anchor" href="#ai语音交互抖音小程序" aria-hidden="true">#</a> AI语音交互抖音小程序</h3><p>我和我的团队在抖音上开发了一款小程序，可以实现语音对话功能，实现了数字人的一部分功能。 demo如下：</p><p><video src="https://www.bilibili.com/video/BV1qu411H7Fm/" width="720" height="360" controls></video></p><p>其具体的实现逻辑如下：</p><figure><img src="'+_+'" alt="语音小程序.png" tabindex="0" loading="lazy"><figcaption>语音小程序.png</figcaption></figure><h3 id="数字人相关" tabindex="-1"><a class="header-anchor" href="#数字人相关" aria-hidden="true">#</a> 数字人相关</h3><p>数字人和数字孪生在GPT出现之后便非常的火热，从直播带货到知识区UP主打造自己的分身，各种技术层出不穷。</p><p>在距离用户最近的展示层，可以是基于unity、meta human、UE等三维建模软件实现的3d人物模型。很多公司也在研究文本/语音驱动3维模型，基于脸部和骨骼模型进行 动作生成。最后是结合语音技术实现一条对话流水线。</p><h4 id="基于unity的数字人构建" tabindex="-1"><a class="header-anchor" href="#基于unity的数字人构建" aria-hidden="true">#</a> 基于Unity的数字人构建</h4><p>下面这个demo是通过unity和gpt实现的数字人</p><p><video src="'+u+'" width="720" height="360" controls></video></p><h2 id="最后" tabindex="-1"><a class="header-anchor" href="#最后" aria-hidden="true">#</a> 最后</h2>',42);function Ae(Te,ye){const n=l("ExternalLinkIcon");return s(),r("div",null,[b,e("p",null,[t("文字推理类的大模型是以GPT为代表的一类通过问题(prompt)推导答案(answer)的大语言模型。 对于Gpt这一类的大语言模型的理解可以通过Ted Chiang发表的一篇文章理解："),e("a",g,[m,a(n)])]),k,w,e("table",null,[S,e("tbody",null,[e("tr",null,[A,e("td",null,[e("a",T,[t("https://beta.openai.com/"),a(n)])]),y,x]),e("tr",null,[I,e("td",null,[e("a",v,[t("https://github.com/facebookresearch/llama"),a(n)])]),V,D]),e("tr",null,[P,e("td",null,[e("a",C,[t("https://claude.ai/"),a(n)])]),G,B]),e("tr",null,[E,e("td",null,[e("a",z,[t("https://tongyi.aliyun.com/"),a(n)])]),J,L]),e("tr",null,[N,e("td",null,[e("a",M,[t("https://maas.aminer.cn/"),a(n)])]),U,j])])]),e("p",null,[t("具体的综合对比可以参考"),e("a",K,[X,a(n)])]),Z,F,e("p",null,[t("功能介绍及演示视频："),e("a",O,[t("https://www.bilibili.com/video/BV1Zz4y1g77J"),a(n)])]),H,e("p",null,[t("Askio的国内官网："),e("a",W,[t("https://www.askio.xyz"),a(n)])]),q,e("p",null,[t("简单易懂的 Diffusion Model 解释："),e("a",Y,[t("https://www.youtube.com/watch?v=1CIpzeNxIhU"),a(n)])]),e("p",null,[t("很棒的Stable Diffusion解释："),e("a",$,[t("https://jalammar.github.io/illustrated-stable-diffusion/"),a(n)])]),e("p",null,[t("同样很棒的SD解释："),e("a",Q,[t("https://medium.com/@steinsfu/stable-diffusion-clearly-explained-ed008044e07e"),a(n)])]),R,e("table",null,[ee,e("tbody",null,[e("tr",null,[te,e("td",null,[e("a",ne,[t("https://github.com/CompVis/stable-diffusion"),a(n)])]),ae,oe]),e("tr",null,[ie,e("td",null,[e("a",se,[t("https://github.com/OpenTalker/SadTalker"),a(n)])]),re,le]),e("tr",null,[he,e("td",null,[e("a",de,[t("https://github.com/facebookresearch/segment-anything"),a(n)])]),pe,ce]),e("tr",null,[_e,e("td",null,[e("a",ue,[t("https://github.com/XingangPan/DragGAN"),a(n)])]),fe,be])])]),ge,me,ke,e("p",null,[t("这是马克制作的第一个公开的AI视频 当一个铃铛说...点我："),e("a",we,[t("https://www.bilibili.com/video/BV1d94y1i7PA/"),a(n)])]),Se])}const Ie=i(f,[["render",Ae],["__file","我用AI做些什么.html.vue"]]);export{Ie as default};
